{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkEunHyeok/AI_Study/blob/main/NLP/GPT2_Chatbot_Pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dRXOhAngcqk",
        "outputId": "3dd223bb-9c91-45e0-b4b8-1b7dd5c0a52d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  9 15:37:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    32W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uls6fXiwQvWa",
        "outputId": "0754c3d0-3f2a-475a-b83b-d6fa9d213aea"
      },
      "source": [
        "!pip install tqdm\n",
        "!pip install kobert-transformers==0.4.1\n",
        "!pip install kogpt2-transformers==0.3.0\n",
        "!pip install transformers==3.0.2\n",
        "!pip install torch\n",
        "!pip install tokenizers==0.8.1rc1\n",
        "!pip install kss"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kobert-transformers==0.4.1 in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers==0.4.1) (1.11.0+cu113)\n",
            "Requirement already satisfied: transformers>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers==0.4.1) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->kobert-transformers==0.4.1) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (0.1.96)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (21.3)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (0.8.1rc1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (1.21.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (0.0.53)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.9.1->kobert-transformers==0.4.1) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.9.1->kobert-transformers==0.4.1) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.9.1->kobert-transformers==0.4.1) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.9.1->kobert-transformers==0.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.9.1->kobert-transformers==0.4.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.9.1->kobert-transformers==0.4.1) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers==0.4.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers==0.4.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.9.1->kobert-transformers==0.4.1) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kogpt2-transformers==0.3.0 in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: tokenizers>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from kogpt2-transformers==0.3.0) (0.8.1rc1)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from kogpt2-transformers==0.3.0) (3.0.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from kogpt2-transformers==0.3.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->kogpt2-transformers==0.3.0) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (2022.6.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (0.1.96)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->kogpt2-transformers==0.3.0) (0.0.53)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=3.0.0->kogpt2-transformers==0.3.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->kogpt2-transformers==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->kogpt2-transformers==0.3.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->kogpt2-transformers==0.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->kogpt2-transformers==0.3.0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->kogpt2-transformers==0.3.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->kogpt2-transformers==0.3.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->kogpt2-transformers==0.3.0) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==3.0.2 in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2022.6.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.6)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.8.1rc1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.0.53)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2022.6.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers==0.8.1rc1 in /usr/local/lib/python3.7/dist-packages (0.8.1rc1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kss in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2022.6.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from kss) (1.7.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from kss) (8.13.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_NIHOQjPWdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184eb990-31ac-4ad9-bfb5-eb4836cca078"
      },
      "source": [
        "# 구글 드라이브 연결\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "path = \"gdrive/My Drive/Colab Notebooks/HelloNewWorld/gpt/\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import dataloader, Dataset\n",
        "from kogpt2_transformers import get_kogpt2_tokenizer, get_kogpt2_model\n",
        "\n",
        "from transformers import glue_compute_metrics as compute_metrics\n",
        "from transformers import glue_output_modes as output_modes\n",
        "from transformers import glue_processors as processors\n",
        "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
        "\n",
        "import torch.nn.utils.prune as prune"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 로깅 준비\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.WARN)\n",
        "\n",
        "logging.getLogger(\"transformers.modeling_utils\").setLevel(\n",
        "                    logging.WARN)  # 로깅 줄이기\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRhTGfR_hXm6",
        "outputId": "cb0a05fe-7ac3-41e8-80f5-1194e364dcdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_num_threads(1)\n",
        "print(torch.__config__.parallel_info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zch1YM4uhi82",
        "outputId": "fea50827-df32-4617-82b5-3d2f40baf3e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATen/Parallel:\n",
            "\tat::get_num_threads() : 1\n",
            "\tat::get_num_interop_threads() : 2\n",
            "OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "\tomp_get_max_threads() : 1\n",
            "Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "\tmkl_get_max_threads() : 1\n",
            "Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
            "std::thread::hardware_concurrency() : 4\n",
            "Environment variables:\n",
            "\tOMP_NUM_THREADS : [not set]\n",
            "\tMKL_NUM_THREADS : [not set]\n",
            "ATen parallel backend: OpenMP\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA2ElX1QQXWf"
      },
      "source": [
        "# !python3 '/content/gdrive/My Drive/Colab Notebooks/HelloNewWorld/gpt/preprocess/training_data.py'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaOwgspT1sy-"
      },
      "source": [
        "class DialogKoGPT2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DialogKoGPT2, self).__init__()\n",
        "    self.kogpt2 = get_kogpt2_model()\n",
        "\n",
        "  def generate(self,\n",
        "               input_ids,\n",
        "               do_sample=True,\n",
        "               max_length= 40,\n",
        "               top_p=0.92,\n",
        "               top_k=50,\n",
        "               temperature= 0.6,\n",
        "               no_repeat_ngram_size =None,\n",
        "               num_return_sequences=3,\n",
        "               early_stopping=False,\n",
        "               ):\n",
        "    return self.kogpt2.generate(input_ids,\n",
        "               do_sample=do_sample,\n",
        "               max_length=max_length,\n",
        "               top_p = top_p,\n",
        "               top_k=top_k,\n",
        "               temperature=temperature,\n",
        "               no_repeat_ngram_size= no_repeat_ngram_size,\n",
        "               num_return_sequences=num_return_sequences,\n",
        "               early_stopping = early_stopping,\n",
        "              )\n",
        "\n",
        "  def forward(self, input, labels = None):\n",
        "    if labels is not None:\n",
        "      outputs = self.kogpt2(input, labels=labels)\n",
        "    else:\n",
        "      outputs = self.kogpt2(input)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K30UojjknXLi"
      },
      "source": [
        "class WellnessAutoRegressiveDataset(Dataset):\n",
        "  \"\"\"Wellness Auto Regressive Dataset\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               file_path = path+\"data/wellness_dialog_for_autoregressive.txt\",\n",
        "               n_ctx = 1024\n",
        "               ):\n",
        "    self.file_path = file_path\n",
        "    self.data =[]\n",
        "    self.tokenizer = get_kogpt2_tokenizer()\n",
        "\n",
        "\n",
        "    bos_token_id = [self.tokenizer.bos_token_id]\n",
        "    eos_token_id = [self.tokenizer.eos_token_id]\n",
        "    pad_token_id = [self.tokenizer.pad_token_id]\n",
        "\n",
        "    file = open(self.file_path, 'r', encoding='utf-8')\n",
        "\n",
        "    while True:\n",
        "      line = file.readline()\n",
        "      if not line:\n",
        "        break\n",
        "      datas = line.split(\"\\t\")\n",
        "      index_of_words = bos_token_id +self.tokenizer.encode(datas[0]) + eos_token_id + bos_token_id + self.tokenizer.encode(datas[1][:-1])+ eos_token_id\n",
        "      pad_token_len = n_ctx - len(index_of_words)\n",
        "\n",
        "      index_of_words += pad_token_id * pad_token_len\n",
        "\n",
        "      self.data.append(index_of_words)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    item = self.data[index]\n",
        "    return item"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzn7sY36nZ_u"
      },
      "source": [
        "dataset = WellnessAutoRegressiveDataset()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path=\"gdrive/My Drive/Colab Notebooks/HelloNewWorld/gpt\"\n",
        "data_path = f\"{root_path}/data/chatbot_wellness_dialog_for_autoregressive.txt\"\n",
        "checkpoint_path =f\"{root_path}/checkpoint\"\n",
        "load_ckpt_path = f\"{checkpoint_path}/kogpt2-20220710.pth\"\n",
        "save_ckpt_path = f\"{checkpoint_path}/kogpt2-20220710-add-chatbotdata.pth\"\n",
        "\n",
        "n_epoch = 3         # Num of Epoch\n",
        "batch_size = 2      # 배치 사이즈\n",
        "ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(ctx)\n",
        "save_step = 500 # 학습 저장 주기\n",
        "learning_rate = 5e-5  # Learning Rate\n",
        "\n",
        "dataset= WellnessAutoRegressiveDataset(data_path)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "csdO8GkofCi3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DialogKoGPT2()"
      ],
      "metadata": {
        "id": "6x4c94_QfD4Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아직 Pruning이 적용되지 않은 모델 구조 출력\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z53GArtWDhs",
        "outputId": "f80ee8da-6619-48b6-884c-9640a3a5bc5a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DialogKoGPT2(\n",
              "  (kogpt2): GPT2LMHeadModel(\n",
              "    (transformer): GPT2Model(\n",
              "      (wte): Embedding(50000, 768)\n",
              "      (wpe): Embedding(1024, 768)\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "      (h): ModuleList(\n",
              "        (0): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=768, out_features=50000, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block이 12개 중첩되는 형태이므로 하나만 출력해봄\n",
        "model.kogpt2.transformer.h[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKs6DvIyWIy9",
        "outputId": "fab3521c-4ac8-4eb7-cd2a-1a21fb02cd92"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Block(\n",
              "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (attn): Attention(\n",
              "    (c_attn): Conv1D()\n",
              "    (c_proj): Conv1D()\n",
              "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (mlp): MLP(\n",
              "    (c_fc): Conv1D()\n",
              "    (c_proj): Conv1D()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block의 attention에서 Pruning을 진행하므로 attention 모듈만 살펴보기\n",
        "model.kogpt2.transformer.h[0].attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpWZzJrOXkjN",
        "outputId": "224cd0e7-bb3a-480f-b160-0c31820c20e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Attention(\n",
              "  (c_attn): Conv1D()\n",
              "  (c_proj): Conv1D()\n",
              "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# attention모듈의 c_attn << Pruning을 진행하기 위해 module로 저장\n",
        "module = model.kogpt2.transformer.h[0].attn.c_attn"
      ],
      "metadata": {
        "id": "Qs32pjxYajAA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c_attn 파라미터에는 weight, bias가 존재함.\n",
        "# 현재 named_buffers()에는 아무것도 존재하지 않음.\n",
        "list(module.named_parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucYDEVSsa4pT",
        "outputId": "c3ba404d-a440-4196-e1db-82a8c8dc62b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('weight', Parameter containing:\n",
              "  tensor([[ 0.3049,  0.1613, -0.2721,  ...,  0.0723, -0.0648, -0.0751],\n",
              "          [-0.0974, -0.2858, -0.0168,  ...,  0.0236,  0.0090,  0.0111],\n",
              "          [ 0.2382, -0.7249,  0.1719,  ...,  0.0373, -0.0615,  0.0319],\n",
              "          ...,\n",
              "          [-0.4462, -0.3731, -0.5665,  ...,  0.0153, -0.0273, -0.0193],\n",
              "          [ 0.4190,  0.2665, -0.1696,  ..., -0.0173,  0.0615,  0.0008],\n",
              "          [-0.3748,  0.0937,  0.5369,  ..., -0.0767, -0.0558, -0.0247]],\n",
              "         requires_grad=True)), ('bias', Parameter containing:\n",
              "  tensor([ 0.3300,  0.7072, -0.2997,  ...,  0.0008, -0.0028,  0.0023],\n",
              "         requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prune 모듈을 활용해 unstructured pruning 적용.\n",
        "# 임의로 30%의 파라미터에 pruning을 적용함\n",
        "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1HjISD9bTQ5",
        "outputId": "1f4fe33a-1ea6-437b-e91b-4c866ae7f656"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv1D()"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(module.named_parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-ndhBeAbdEF",
        "outputId": "bb8abc42-a1d6-44f3-f604-47b425f7110d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bias', Parameter containing:\n",
              "  tensor([ 0.3300,  0.7072, -0.2997,  ...,  0.0008, -0.0028,  0.0023],\n",
              "         requires_grad=True)), ('weight_orig', Parameter containing:\n",
              "  tensor([[ 0.3049,  0.1613, -0.2721,  ...,  0.0723, -0.0648, -0.0751],\n",
              "          [-0.0974, -0.2858, -0.0168,  ...,  0.0236,  0.0090,  0.0111],\n",
              "          [ 0.2382, -0.7249,  0.1719,  ...,  0.0373, -0.0615,  0.0319],\n",
              "          ...,\n",
              "          [-0.4462, -0.3731, -0.5665,  ...,  0.0153, -0.0273, -0.0193],\n",
              "          [ 0.4190,  0.2665, -0.1696,  ..., -0.0173,  0.0615,  0.0008],\n",
              "          [-0.3748,  0.0937,  0.5369,  ..., -0.0767, -0.0558, -0.0247]],\n",
              "         requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pruning에 의해 생성된 weight_mask\n",
        "list(module.named_buffers())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s4yiqHdbjHM",
        "outputId": "62db7601-9df1-4d42-f62a-35ceb0a75817"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('weight_mask', tensor([[1., 1., 1.,  ..., 1., 1., 0.],\n",
              "          [1., 1., 1.,  ..., 0., 1., 1.],\n",
              "          [0., 0., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 0., 1.,  ..., 1., 0., 1.],\n",
              "          [0., 1., 0.,  ..., 1., 1., 0.],\n",
              "          [0., 0., 1.,  ..., 0., 0., 1.]]))]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weight는 더이상 파라미터로 관리되는 것이 아닌 속성으로 관리됨.\n",
        "module.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd1Oe45ZbrZX",
        "outputId": "df8aa74b-64b5-40a7-f553-098ab1f64888"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3049,  0.1613, -0.2721,  ...,  0.0723, -0.0648, -0.0000],\n",
              "        [-0.0974, -0.2858, -0.0168,  ...,  0.0000,  0.0090,  0.0111],\n",
              "        [ 0.0000, -0.0000,  0.1719,  ...,  0.0373, -0.0615,  0.0319],\n",
              "        ...,\n",
              "        [-0.4462, -0.0000, -0.5665,  ...,  0.0153, -0.0000, -0.0193],\n",
              "        [ 0.0000,  0.2665, -0.0000,  ..., -0.0173,  0.0615,  0.0000],\n",
              "        [-0.0000,  0.0000,  0.5369,  ..., -0.0000, -0.0000, -0.0247]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞서 적용한 pruning을 순전파 이전에 적용하기 위해 적용함.\n",
        "module._forward_pre_hooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxis6gc7bt_o",
        "outputId": "1a42284f-2f04-46ca-8ff1-a453ce0cc025"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured at 0x7f37f59b4850>)])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# l1_unstructured를 이용해 bias에도 Pruning을 적용함.\n",
        "prune.l1_unstructured(module, name='bias', amount=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKWSPBNjcL4O",
        "outputId": "71fb36b4-ff1d-4811-f3fe-15c3036f3184"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv1D()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(module.named_parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQBxbL5dcTOk",
        "outputId": "27a82045-1750-4d25-d683-867c66fd4881"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('weight_orig', Parameter containing:\n",
              "  tensor([[ 0.3049,  0.1613, -0.2721,  ...,  0.0723, -0.0648, -0.0751],\n",
              "          [-0.0974, -0.2858, -0.0168,  ...,  0.0236,  0.0090,  0.0111],\n",
              "          [ 0.2382, -0.7249,  0.1719,  ...,  0.0373, -0.0615,  0.0319],\n",
              "          ...,\n",
              "          [-0.4462, -0.3731, -0.5665,  ...,  0.0153, -0.0273, -0.0193],\n",
              "          [ 0.4190,  0.2665, -0.1696,  ..., -0.0173,  0.0615,  0.0008],\n",
              "          [-0.3748,  0.0937,  0.5369,  ..., -0.0767, -0.0558, -0.0247]],\n",
              "         requires_grad=True)), ('bias_orig', Parameter containing:\n",
              "  tensor([ 0.3300,  0.7072, -0.2997,  ...,  0.0008, -0.0028,  0.0023],\n",
              "         requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(module.named_buffers())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btkjxqmkcZD8",
        "outputId": "badeae47-67d8-4587-8662-b2dac41ec7c3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('weight_mask', tensor([[1., 1., 1.,  ..., 1., 1., 0.],\n",
              "          [1., 1., 1.,  ..., 0., 1., 1.],\n",
              "          [0., 0., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 0., 1.,  ..., 1., 0., 1.],\n",
              "          [0., 1., 0.,  ..., 1., 1., 0.],\n",
              "          [0., 0., 1.,  ..., 0., 0., 1.]])),\n",
              " ('bias_mask', tensor([1., 1., 1.,  ..., 1., 1., 1.]))]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "module.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTujBguechwH",
        "outputId": "e054ed39-1b71-4ea6-b081-94758b8b4cec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3300,  0.7072, -0.2997,  ...,  0.0008, -0.0028,  0.0023],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "module.bias.size(), (module.bias == 0).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXboITricmqh",
        "outputId": "29742e66-f032-40d5-f290-71b0fb44fa9c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2304]), tensor(50))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# module의 _forward_pre_hooks에도 2개의 pre_hook이 존재하는 것을 알 수 있음.\n",
        "# Pruning을 중첩해서 사용 가능함\n",
        "# 중첩의 의미는, 여러 pruning mask를 적용해서 사용 가능 하단 소리.\n",
        "\n",
        "module._forward_pre_hooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdV7Hsa2cohe",
        "outputId": "9aad37f0-ae92-4fd7-96d5-2b053e00dc91"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured at 0x7f37f59b4850>),\n",
              "             (1, <torch.nn.utils.prune.L1Unstructured at 0x7f37f2097b50>)])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.kogpt2.transformer.h[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6vTON6ohqS3",
        "outputId": "14623fc0-04fc-496b-be4b-f107eb726833"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Block(\n",
              "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (attn): Attention(\n",
              "    (c_attn): Conv1D()\n",
              "    (c_proj): Conv1D()\n",
              "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (mlp): MLP(\n",
              "    (c_fc): Conv1D()\n",
              "    (c_proj): Conv1D()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Pruning 적용\n",
        "\n",
        "final_model = DialogKoGPT2()\n",
        "final_model.to(device)\n",
        "\n",
        "parameters_to_prune = ()\n",
        "for i in range(12):\n",
        "    parameters_to_prune += (\n",
        "        (final_model.kogpt2.transformer.h[i].attn.c_attn, 'weight'),\n",
        "        (final_model.kogpt2.transformer.h[i].attn.c_proj, 'weight'),\n",
        "    )\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "DOQ_wt6shdP4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Pruning을 통해 전체 Sparsity를 20%로 만들 수 있음을 알 수 있음.\n",
        "\n",
        "for i in range(12):\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th c_attn weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(final_model.kogpt2.transformer.h[i].attn.c_attn.weight == 0))\n",
        "            / float(final_model.kogpt2.transformer.h[i].attn.c_attn.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th c_proj weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(final_model.kogpt2.transformer.h[i].attn.c_proj.weight == 0))\n",
        "            / float(final_model.kogpt2.transformer.h[i].attn.c_proj.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print()\n",
        "\n",
        "    \n",
        "numerator, denominator = 0, 0\n",
        "for i in range(12):\n",
        "    numerator += torch.sum(final_model.kogpt2.transformer.h[i].attn.c_attn.weight == 0)\n",
        "    numerator += torch.sum(final_model.kogpt2.transformer.h[i].attn.c_proj.weight == 0)\n",
        "\n",
        "    denominator += final_model.kogpt2.transformer.h[i].attn.c_attn.weight.nelement()\n",
        "    denominator += final_model.kogpt2.transformer.h[i].attn.c_proj.weight.nelement()\n",
        "    \n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVmI_hyaiJh_",
        "outputId": "7aca3425-983b-4a80-8069-2fb8ee79ad27"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in Layer 1-th c_attn weight: 28.47%\n",
            "Sparsity in Layer 1-th c_proj weight: 65.74%\n",
            "\n",
            "Sparsity in Layer 2-th c_attn weight: 20.61%\n",
            "Sparsity in Layer 2-th c_proj weight: 24.94%\n",
            "\n",
            "Sparsity in Layer 3-th c_attn weight: 18.73%\n",
            "Sparsity in Layer 3-th c_proj weight: 27.17%\n",
            "\n",
            "Sparsity in Layer 4-th c_attn weight: 17.68%\n",
            "Sparsity in Layer 4-th c_proj weight: 23.86%\n",
            "\n",
            "Sparsity in Layer 5-th c_attn weight: 17.33%\n",
            "Sparsity in Layer 5-th c_proj weight: 21.64%\n",
            "\n",
            "Sparsity in Layer 6-th c_attn weight: 17.04%\n",
            "Sparsity in Layer 6-th c_proj weight: 19.34%\n",
            "\n",
            "Sparsity in Layer 7-th c_attn weight: 17.24%\n",
            "Sparsity in Layer 7-th c_proj weight: 18.92%\n",
            "\n",
            "Sparsity in Layer 8-th c_attn weight: 17.60%\n",
            "Sparsity in Layer 8-th c_proj weight: 19.29%\n",
            "\n",
            "Sparsity in Layer 9-th c_attn weight: 16.98%\n",
            "Sparsity in Layer 9-th c_proj weight: 19.14%\n",
            "\n",
            "Sparsity in Layer 10-th c_attn weight: 17.09%\n",
            "Sparsity in Layer 10-th c_proj weight: 17.16%\n",
            "\n",
            "Sparsity in Layer 11-th c_attn weight: 17.65%\n",
            "Sparsity in Layer 11-th c_proj weight: 15.29%\n",
            "\n",
            "Sparsity in Layer 12-th c_attn weight: 17.77%\n",
            "Sparsity in Layer 12-th c_proj weight: 14.94%\n",
            "\n",
            "Global sparsity: 20.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAVo-t80ncml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a850f6-32e4-4ab8-b0c9-29b7278d58c4"
      },
      "source": [
        "loss_fct = torch.nn.CrossEntropyLoss(ignore_index=3)\n",
        "optimizer = torch.optim.Adam(final_model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses =[]\n",
        "for epoch in range(n_epoch):\n",
        "    count = 0\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data = torch.stack(data)  # list of Tensor로 구성되어 있기 때문에 list를 stack을 통해 변환해준다.\n",
        "            data = data.transpose(1, 0)\n",
        "            data= data.to(ctx)\n",
        "\n",
        "            outputs = final_model(data, labels=data)\n",
        "            _, logits = outputs[:2]\n",
        "\n",
        "            # Shift so that tokens < n predict n\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = data[..., 1:].contiguous()\n",
        "\n",
        "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # if count % 10 == 0:\n",
        "            #     print('epoch no.{} train no.{}  loss = {}'.format(epoch, count + 1, loss))\n",
        "            if (count > 0 and count % save_step == 0) or (len(data) < batch_size):\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'train_no': count,\n",
        "                    'model_state_dict': final_model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(), \n",
        "                    'loss': loss\n",
        "                }, save_ckpt_path)\n",
        "            count += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss.item():.3f} ({np.mean(losses):.3f})\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train(0): 100%|██████████| 13840/13840 [1:33:12<00:00,  2.47it/s, Loss: 3.541 (2.336)]\n",
            "Train(1): 100%|██████████| 13840/13840 [1:33:21<00:00,  2.47it/s, Loss: 0.911 (1.892)]\n",
            "Train(2): 100%|██████████| 13840/13840 [1:33:31<00:00,  2.47it/s, Loss: 0.853 (1.602)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'train_no': count,\n",
        "    'model_state_dict': final_model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(), \n",
        "    'loss': loss\n",
        "}, save_ckpt_path)"
      ],
      "metadata": {
        "id": "WOT2yBWdlKr_"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}