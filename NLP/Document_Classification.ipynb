{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Document_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPILbpWk571j6WXaO7NoT+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkEunHyeok/AI_Study/blob/main/NLP/Document_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcgLNnIwgaCD",
        "outputId": "a44bcf95-69da-4f72-f96c-0a34dc62a47e"
      },
      "source": [
        "!pip3 install konlpy\n",
        "!pip3 install jamo"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 36.3 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Collecting jamo\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: jamo\n",
            "Successfully installed jamo-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCWchEWaffI9"
      },
      "source": [
        "import requests # 파파고 번역 api 사용\n",
        "import re\n",
        "import jpype\n",
        "import requests\n",
        "from gensim.models import Word2Vec\n",
        "from jamo import h2j, j2hcj\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEVZUIalBnN",
        "outputId": "5db9c6d9-9a3d-43eb-dee0-1b3f372b30d1"
      },
      "source": [
        "# 구글 드라이브 연결\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "path = \"gdrive/My Drive/Colab Notebooks/PMS/\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLo7SrakgvbN"
      },
      "source": [
        "# 파일 확장자 및 특수문자 제거 후 형태소 명사 단위로 분석\n",
        "\n",
        "def morpheme(file_name):\n",
        "  okt = Okt()\n",
        "\n",
        "  no_extension_file_name = file_name.rsplit('.', 1)[0] \n",
        "  cleaned_file_name = re.sub('[-=+,_#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]',\n",
        "                             '', no_extension_file_name)\n",
        "\n",
        "  return cleaned_file_name"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt_ze3vbdgha"
      },
      "source": [
        "# 영어 문장 한글로 번역\n",
        "\n",
        "def get_translate_ko(text):\n",
        "    client_id = \"fSuwQC7wzKdKWD4f0Gbl\" # <-- client_id 기입\n",
        "    client_secret = \"upCLLCyDRI\" # <-- client_secret 기입\n",
        "\n",
        "    data = {'text' : text,\n",
        "            'source' : 'en',\n",
        "            'target': 'ko'}\n",
        "\n",
        "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
        "\n",
        "    header = {\"X-Naver-Client-Id\":client_id,\n",
        "              \"X-Naver-Client-Secret\":client_secret}\n",
        "\n",
        "    response = requests.post(url, headers=header, data=data)\n",
        "    rescode = response.status_code\n",
        "\n",
        "    if(rescode==200):\n",
        "        send_data = response.json()\n",
        "        trans_data = (send_data['message']['result']['translatedText'])\n",
        "        return trans_data\n",
        "    else:\n",
        "        print(\"Error Code:\" , rescode)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZCw7uTgRFb"
      },
      "source": [
        "# 한글 문장 영어로 번역\n",
        "\n",
        "def get_translate_eng(text):\n",
        "    client_id = \"fSuwQC7wzKdKWD4f0Gbl\" # <-- client_id 기입\n",
        "    client_secret = \"upCLLCyDRI\" # <-- client_secret 기입\n",
        "\n",
        "    data = {'text' : text,\n",
        "            'source' : 'ko',\n",
        "            'target': 'en'}\n",
        "\n",
        "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
        "\n",
        "    header = {\"X-Naver-Client-Id\":client_id,\n",
        "              \"X-Naver-Client-Secret\":client_secret}\n",
        "\n",
        "    response = requests.post(url, headers=header, data=data)\n",
        "    rescode = response.status_code\n",
        "\n",
        "    if(rescode==200):\n",
        "        send_data = response.json()\n",
        "        trans_data = (send_data['message']['result']['translatedText'])\n",
        "        return trans_data\n",
        "    else:\n",
        "        print(\"Error Code:\" , rescode)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n1LHx4PfCOe"
      },
      "source": [
        "# 데이터 전처리 함수\n",
        "\n",
        "def data_preprocess(data_list): # 파일 리스트 / 디렉토리 리스트\n",
        "    preprocessed_list = data_list\n",
        "    tmp_data=\"\"\n",
        "    result = []\n",
        "\n",
        "    # 형태소 분석, 특수기호 제거\n",
        "    for data_index in range(len(preprocessed_list)):\n",
        "        split_data = morpheme(preprocessed_list[data_index])\n",
        "        preprocessed_list[data_index] = split_data\n",
        "    \n",
        "    # 번역 api : 영어 번역, 띄어쓰기\n",
        "    for index in range(len(preprocessed_list)):\n",
        "      # 영어 거쳐서 한국어 번역하면 정확도 높은 대신\n",
        "      # 시간 오래걸리고 api 일일 사용량 제한 더 잘걸림\n",
        "      eng_list = get_translate_eng(preprocessed_list[index])\n",
        "      ko_list = get_translate_ko(eng_list)\n",
        "      # ko_list = get_translate_ko(preprocessed_list[index])\n",
        "      result.append(ko_list)\n",
        "    return result"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgdejit3hVvX"
      },
      "source": [
        "# 폴더 안에 들어간 파일들의 내용 저장\n",
        "\n",
        "def save_classificated_file(index_dict, file_list, directory_list):\n",
        "    result_dict = {}\n",
        "\n",
        "    for key, value in index_dict.items():\n",
        "        result_dict[file_list[key]] = directory_list[value]\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhTJyCrIhdfL"
      },
      "source": [
        "# 매칭된 파일 제거\n",
        "\n",
        "def rm_classificated_file(index_dict,file_list):  # 매칭된 파일 제거\n",
        "    data_name = []\n",
        "    for index in list(index_dict.keys()):\n",
        "        data_name.append(file_list[index])\n",
        "\n",
        "    file_list =  [x for x in file_list if x not in (data_name)]\n",
        "\n",
        "    return file_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA1ASd0Fgl6O"
      },
      "source": [
        "# 단순 유사도 검사\n",
        "# 파일명과 카테고리명이 같으면 그 폴더 안에 넣어줌\n",
        "\n",
        "def simplest_classification(directory_list, file_list):  # 단어 유사도 검사 => index return해서 제거하는 방법을 쓴다.\n",
        "    tmp_dict = {}\n",
        "    if jpype.isJVMStarted():\n",
        "      jpype.attachThreadToJVM()\n",
        "    okt = Okt()\n",
        "    classificated_dir_index = 0\n",
        "    for file_index in range(len(file_list)):\n",
        "        file_morphs = okt.morphs(file_list[file_index])\n",
        "        \n",
        "        max_weight = 0\n",
        "        for dir_index in range(len(directory_list)): # 디렉토리 갯수 : 3\n",
        "            dir_morphs = okt.morphs(directory_list[dir_index])\n",
        "            tmp_weight = 0\n",
        "            for file_element in file_morphs: # 형태분석한 파일 갯수\n",
        "                for dir_element in dir_morphs:\n",
        "                    \n",
        "                    if (dir_element == file_element) and (check_format(dir_element) == ('kor')):\n",
        "                        tmp_weight += 2      \n",
        "                    \t#한글로 되있을 경우 가중치 2\n",
        "                    elif ((file_element in dir_element) and (check_format(dir_element) == ('num'))):\n",
        "                        tmp_weight += 1\n",
        "                        #영어로 되있을 경우 가중치 1\n",
        "                        \n",
        "            if (tmp_weight > max_weight):\n",
        "                max_weight = tmp_weight\n",
        "                classificated_dir_index = dir_index\n",
        "        if max_weight > 0:\n",
        "            tmp_dict[file_index] = classificated_dir_index\n",
        "\n",
        "    return tmp_dict"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ2fleL2sRjT"
      },
      "source": [
        "# 한글과 숫자를 판단하고 가중치를 넣어주는 함수\n",
        "# 숫자보다 한글의 가중치가 높게 설정\n",
        "\n",
        "def check_format(input): # 한국어 , 영어 , 숫자 형태 분석\n",
        "    value = input[0]\n",
        "    if ord('가') <= ord(value) <= ord('힣'):\n",
        "        return 'kor'\n",
        "    elif value.isdigit():\n",
        "        return 'num'\n",
        "    elif value.isalpha():\n",
        "        return 'eng'\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyaG8uRiheQy"
      },
      "source": [
        "# Word2Vec 유사도 측정\n",
        "# 제목과 카테고리명 사이의 유사도를 측정, 퍼센테이지 출력\n",
        "\n",
        "def word2vec_similarity(directory_list, file_list):\n",
        "    model = Word2Vec.load(path+'ko.bin')\n",
        "\n",
        "    tmp_dict = {}\n",
        "    classificated_dir_index = 0\n",
        "    if jpype.isJVMStarted():\n",
        "      jpype.attachThreadToJVM()\n",
        "    okt = Okt() # 형태소 분석\n",
        "    for file_index in range(len(file_list)):\n",
        "        max_similarity = 0\n",
        "        file_morphs = okt.morphs(file_list[file_index])\n",
        "        for dir_index in range(len(directory_list)):\n",
        "            dir_morphs = okt.morphs(directory_list[dir_index])\n",
        "            tmp_similarity = 0\n",
        "            for file_element in file_morphs:\n",
        "                for dir_element in dir_morphs:\n",
        "                    if check_format(file_element) == 'kor' and check_format(dir_element) == 'kor':\n",
        "                        try:\n",
        "                            tmp_similarity = model.similarity(file_element, dir_element)\n",
        "                        except KeyError:\n",
        "                            pass\n",
        "                if tmp_similarity > max_similarity:  # 유사도 수치는 사용자가 설정\n",
        "                    max_similarity = tmp_similarity\n",
        "                    classificated_dir_index = dir_index\n",
        "\n",
        "            tmp_dict[file_index] = classificated_dir_index\n",
        "\n",
        "    return tmp_dict"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwsI-_FRhjWM"
      },
      "source": [
        "# 자모 단위를 이용한 유사도 검사\n",
        "\n",
        "def Phonology_classification(directory_list, file_list):\n",
        "    trans_file_jumo = []\n",
        "    trans_folder_jumo = []\n",
        "    equl_count = [[0 for i in range(len(file_list))] for i in range(len(directory_list))]\n",
        "    result_dict = {}\n",
        "\n",
        "    for i in file_list:\n",
        "        a = j2hcj(h2j(i))\n",
        "        line = []\n",
        "        for j in a:\n",
        "            line.append(j2hcj(h2j(j)))\n",
        "        trans_file_jumo.append(line)\n",
        "\n",
        "    for i in directory_list:\n",
        "        a = j2hcj(h2j(i))\n",
        "        line = []\n",
        "        for j in a:\n",
        "            line.append(j2hcj(h2j(j)))\n",
        "        trans_folder_jumo.append(line)\n",
        "\n",
        "    for i in range(len(directory_list)):\n",
        "        for j in range(len(file_list)):\n",
        "            for k in trans_file_jumo[j]:\n",
        "                if k in trans_folder_jumo[i]:\n",
        "                    equl_count[i][j] += 1\n",
        "\n",
        "    for i in range(len(directory_list)):\n",
        "        for j in range(len(file_list)):\n",
        "            if len(trans_folder_jumo[i]) <= equl_count[i][j]:\n",
        "                result_dict[j] = i\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNuf_5keiM4J"
      },
      "source": [
        "def dict_to_list(dict):\n",
        "    result = []\n",
        "\n",
        "    for key, value in dict.items():\n",
        "        tmp = str(value) + \"/\"+ str(key)\n",
        "        result.append(tmp)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGuxNSyGiHNT"
      },
      "source": [
        "# 기타 폴더\n",
        "# 분류가 안된 파일들을 기타로 분류해줌\n",
        "\n",
        "def except_directory(file_list):\n",
        "    out_of_classification = \"except_directory\"\n",
        "    result_dict = {}\n",
        "\n",
        "    for file in file_list:\n",
        "        result_dict[file] = out_of_classification\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MphdSiPtiOSt"
      },
      "source": [
        "# 분류될 카테고리명\n",
        "directory_list = ['넷마블', '대통령', '민주당', '모모랜드', '레드벨벳', '빅히트', '소프트', '코스피', '텔레콤', '트롯', '포토']\n",
        "# 분류할 문서 이름\n",
        "file_list = ['코스피외국인개인매수에코앞까지코스닥돌파.txt', '더불어민주당미래입법과제상임위간사단연석회의.txt', '자급제아이폰분실보험가입일부터가능.txt', '모모랜드주이자가격리붐대신스페셜등장어마어마하게떨려붐붐파워.txt', '넷마블월드시즌챕터업데이트.txt', '코스피사흘연속사상최고치경신.txt', '민주당미래입법과제상임위간사단연석회의.txt', '텔레콤맵안드로이드오토베타테스트론칭.txt', '놀면뭐하니톱귀유재석추억의주크박스오픈만여명과깜짝라이브.txt', '발라드그룹순순희신곡전부다주지말걸발표.txt', '트롯신홍원빈테스형으로열정무대패자부활전탈락에도극찬.txt', '넷마블월드새로운챕터성카드추가.txt', '코스피는오르고환율은내리고.txt', '자급제아이폰써도분실보험가입가능해진다.txt', '장동민배다해선넘는사생활피해에곤혹이슈톡.txt', '코스피사상최고치경신.txt', '다시뒤집힌전동킥보드법무면허규제법행안위통과.txt', '빅히트레이블즈가지테마로펼쳐진다.txt', '자급제아이폰일부터분실보험가입가능.txt', '코스피사상최고치.txt', '텔레콤자급제아이폰도분실보험가입된다.txt', '소프트웨이브디지털전환사이버보안이핵심.txt', '이낙연공수처법반드시완수많이인내했고결단임박.txt', '세일즈포스고급차브랜드벤틀리에솔루션공급.txt', '코스피다시역대최고가마감.txt', '모모랜드주이붐붐파워대타상큼미모.txt', '코스피종가기준최고치경신.txt', '미래입법과제상임위간사단연석회의참석하는이낙연김태년.txt', '대통령절차적정당성공정성당부추미애징계위연기.txt', '레드벨벳아이린오랜만에근황화보촬영스타.txt', '코스피마감사흘연속사상최고치경신.txt', '코스피일째사상최고원달러환율원대.txt', '소프트웨이브플렌옵틱콘텐츠저작기술.txt', '트롯신이떴다홍원빈테스형으로레전드무대선사.txt', '미래입법과제발언하는이낙연대표.txt', '코스피일연속최고치경신선목전서마감종합.txt', '코스피마감또최고치경신선눈앞.txt', '코스피거침없는질주오르며사흘째최고치경신.txt', '민주당국회자리에아파트짓자는건토건포퓰리즘.txt', '포토하하별후딱끝내고갈게.txt', '표시장거래현황.txt', '크루미디어지콤위시트레이닝센터업무제휴계약체결.txt', '민주당미래입법과제연석회의.txt', '대통령절차적정당공정성강조에징계위일로연기.txt', '코스피하루만에최고치경신.txt', '윤보미김민경비장함감도는마녀들포스터운동신들케미에기대.txt', '발언하는이낙연대표.txt', '대통령이용구징계위원장배제지시했지만공정성논쟁은여전.txt', '미래입법과제상임위간사단연석회의.txt', '자급제아이폰고객도분실보험가입된다.txt', '모모랜드낸시나윤한복전도사뿜뿜.txt', '대화하는이낙연한정애.txt', '텔레콤빅테크마케팅컴퍼니로조직개편.txt', '레드벨벳아이린갑질논란후첫근황미모에물올랐네스타.txt', '코스피최고치경신눈앞삼성전자장중만원첫돌파.txt', '소프트웨이브모아소프트등분석시험도구공개.txt', '빅히트뉴이어스이브라이브.txt', '목요대화참석자와인사하는정세균총리.txt', '코스피사상최고치원달러환율원붕괴.txt', '소프트웨이브혁신기술선보인다스타트업총출동.txt', '소프트웨이브플랫폼부터의료진단시스템까지신기술총출동.txt', '자급제아이폰도일부터분실보험가입가능.txt', '김태희싸이다이아몬드수저스타상위집안연중라이브.txt', '목소리내는여당전의원들추미애가검찰개혁어렵게해.txt', '자급제아이폰분실보험가입월일부터가능.txt', '발언하는김태년원내대표.txt', '코스피일째사상최고치.txt', '코스피사흘연속사상최고치경신선눈앞.txt', '트롯전국체전트로트전쟁서막알리는예고편공개.txt', '코스피역대최고가로마감.txt', '트롯전국체전레전드라인업과함께트로트시대연다.txt', '빅히트패밀리콘서트에서도본다새해카운트다운무대공개.txt', '자급제아이폰도분실보험가능.txt', '민주당권력기관개혁마무리수순야당공수처결사반대.txt', '소프트웨이브국내대표솔루션업계차세대먹거리로미래준비한다.txt', '코스피일째사상최고선코앞.txt', '스브스타남자로살겠다선언한엘리엇페이지에배우자도지지자랑스러워.txt', '단독박명수이찬원밀접접촉자개뼈다귀녹화연기.txt', 'untitled.ui', '민주국민의힘김은혜대변인즉각적인사과촉구.txt', '미래입법과제연석회의참석하는이낙연김태년.txt']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdv22YdMiYfz"
      },
      "source": [
        "# 제목 기반 자동 분류\n",
        "def title_classification(directory_list, file_list):\n",
        "    result_dict = {}\n",
        "    index_dict = {}\n",
        "\n",
        "    origin_directory_list = directory_list.copy()\n",
        "    origin_file_list = file_list.copy()\n",
        "\n",
        "    # 데이터 전처리\n",
        "    tmp_dir_list = data_preprocess(directory_list)\n",
        "    tmp_file_list = data_preprocess(file_list)\n",
        "\n",
        "    # 단순 유사도 검사\n",
        "    index_dict = simplest_classification(tmp_dir_list, tmp_file_list)\n",
        "    ## update\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # Word2Vec를 이용한 유사도 검사\n",
        "    index_dict = word2vec_similarity(tmp_dir_list, tmp_file_list)\n",
        "    ## update\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # 자모단위 유사도 검사\n",
        "    index_dict = Phonology_classification(tmp_dir_list, tmp_file_list)\n",
        "    ## update\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # 기타 분류\n",
        "    result_dict.update(except_directory(origin_file_list))\n",
        "\n",
        "    result_list = dict_to_list(result_dict)\n",
        "    return result_list"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWelqjojxvjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f36611c-f95e-4f18-8e2b-98c3c1dc1b0c"
      },
      "source": [
        "res = title_classification(directory_list, file_list)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llGhKy7psmJ4",
        "outputId": "a224ada8-86a1-42ec-ac00-bbd4fa39e9cb"
      },
      "source": [
        "for i in res:\n",
        "  print(i, end=\"\\n\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "넷마블/코스피외국인개인매수에코앞까지코스닥돌파\n",
            "넷마블/더불어민주당미래입법과제상임위간사단연석회의\n",
            "넷마블/자급제아이폰분실보험가입일부터가능\n",
            "넷마블/모모랜드주이자가격리붐대신스페셜등장어마어마하게떨려붐붐파워\n",
            "넷마블/넷마블월드시즌챕터업데이트\n",
            "넷마블/코스피사흘연속사상최고치경신\n",
            "넷마블/민주당미래입법과제상임위간사단연석회의\n",
            "넷마블/텔레콤맵안드로이드오토베타테스트론칭\n",
            "넷마블/놀면뭐하니톱귀유재석추억의주크박스오픈만여명과깜짝라이브\n",
            "넷마블/발라드그룹순순희신곡전부다주지말걸발표\n",
            "넷마블/트롯신홍원빈테스형으로열정무대패자부활전탈락에도극찬\n",
            "넷마블/넷마블월드새로운챕터성카드추가\n",
            "넷마블/코스피는오르고환율은내리고\n",
            "넷마블/자급제아이폰써도분실보험가입가능해진다\n",
            "넷마블/장동민배다해선넘는사생활피해에곤혹이슈톡\n",
            "넷마블/코스피사상최고치경신\n",
            "넷마블/다시뒤집힌전동킥보드법무면허규제법행안위통과\n",
            "넷마블/빅히트레이블즈가지테마로펼쳐진다\n",
            "넷마블/자급제아이폰일부터분실보험가입가능\n",
            "넷마블/코스피사상최고치\n",
            "넷마블/텔레콤자급제아이폰도분실보험가입된다\n",
            "넷마블/소프트웨이브디지털전환사이버보안이핵심\n",
            "넷마블/이낙연공수처법반드시완수많이인내했고결단임박\n",
            "넷마블/세일즈포스고급차브랜드벤틀리에솔루션공급\n",
            "넷마블/코스피다시역대최고가마감\n",
            "넷마블/모모랜드주이붐붐파워대타상큼미모\n",
            "넷마블/코스피종가기준최고치경신\n",
            "넷마블/미래입법과제상임위간사단연석회의참석하는이낙연김태년\n",
            "넷마블/대통령절차적정당성공정성당부추미애징계위연기\n",
            "넷마블/레드벨벳아이린오랜만에근황화보촬영스타\n",
            "넷마블/코스피마감사흘연속사상최고치경신\n",
            "넷마블/코스피일째사상최고원달러환율원대\n",
            "넷마블/소프트웨이브플렌옵틱콘텐츠저작기술\n",
            "넷마블/트롯신이떴다홍원빈테스형으로레전드무대선사\n",
            "넷마블/미래입법과제발언하는이낙연대표\n",
            "넷마블/코스피일연속최고치경신선목전서마감종합\n",
            "넷마블/코스피마감또최고치경신선눈앞\n",
            "넷마블/코스피거침없는질주오르며사흘째최고치경신\n",
            "넷마블/민주당국회자리에아파트짓자는건토건포퓰리즘\n",
            "넷마블/포토하하별후딱끝내고갈게\n",
            "넷마블/표시장거래현황\n",
            "넷마블/크루미디어지콤위시트레이닝센터업무제휴계약체결\n",
            "넷마블/민주당미래입법과제연석회의\n",
            "넷마블/대통령절차적정당공정성강조에징계위일로연기\n",
            "넷마블/코스피하루만에최고치경신\n",
            "넷마블/윤보미김민경비장함감도는마녀들포스터운동신들케미에기대\n",
            "넷마블/발언하는이낙연대표\n",
            "넷마블/대통령이용구징계위원장배제지시했지만공정성논쟁은여전\n",
            "넷마블/미래입법과제상임위간사단연석회의\n",
            "넷마블/자급제아이폰고객도분실보험가입된다\n",
            "넷마블/모모랜드낸시나윤한복전도사뿜뿜\n",
            "넷마블/대화하는이낙연한정애\n",
            "넷마블/텔레콤빅테크마케팅컴퍼니로조직개편\n",
            "넷마블/레드벨벳아이린갑질논란후첫근황미모에물올랐네스타\n",
            "넷마블/코스피최고치경신눈앞삼성전자장중만원첫돌파\n",
            "넷마블/소프트웨이브모아소프트등분석시험도구공개\n",
            "넷마블/빅히트뉴이어스이브라이브\n",
            "넷마블/목요대화참석자와인사하는정세균총리\n",
            "넷마블/코스피사상최고치원달러환율원붕괴\n",
            "넷마블/소프트웨이브혁신기술선보인다스타트업총출동\n",
            "넷마블/소프트웨이브플랫폼부터의료진단시스템까지신기술총출동\n",
            "넷마블/자급제아이폰도일부터분실보험가입가능\n",
            "넷마블/김태희싸이다이아몬드수저스타상위집안연중라이브\n",
            "넷마블/목소리내는여당전의원들추미애가검찰개혁어렵게해\n",
            "넷마블/자급제아이폰분실보험가입월일부터가능\n",
            "넷마블/발언하는김태년원내대표\n",
            "넷마블/코스피일째사상최고치\n",
            "넷마블/코스피사흘연속사상최고치경신선눈앞\n",
            "넷마블/트롯전국체전트로트전쟁서막알리는예고편공개\n",
            "넷마블/코스피역대최고가로마감\n",
            "넷마블/트롯전국체전레전드라인업과함께트로트시대연다\n",
            "넷마블/빅히트패밀리콘서트에서도본다새해카운트다운무대공개\n",
            "넷마블/자급제아이폰도분실보험가능\n",
            "넷마블/민주당권력기관개혁마무리수순야당공수처결사반대\n",
            "넷마블/소프트웨이브국내대표솔루션업계차세대먹거리로미래준비한다\n",
            "넷마블/코스피일째사상최고선코앞\n",
            "넷마블/스브스타남자로살겠다선언한엘리엇페이지에배우자도지지자랑스러워\n",
            "넷마블/단독박명수이찬원밀접접촉자개뼈다귀녹화연기\n",
            "대통령/untitled\n",
            "대통령/민주국민의힘김은혜대변인즉각적인사과촉구\n",
            "대통령/미래입법과제연석회의참석하는이낙연김태년\n"
          ]
        }
      ]
    }
  ]
}