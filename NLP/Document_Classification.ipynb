{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Document_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJdkqNpPxg/BLiQuFlhKxg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkEunHyeok/AI_Study/blob/main/NLP/Document_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcgLNnIwgaCD",
        "outputId": "999974a7-5f03-434b-de04-c95eb3e11b45"
      },
      "source": [
        "!pip3 install konlpy\n",
        "!pip3 install jamo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 42.5 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Collecting jamo\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: jamo\n",
            "Successfully installed jamo-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCWchEWaffI9"
      },
      "source": [
        "import requests # 파파고 번역 api 사용\n",
        "import re\n",
        "import jpype\n",
        "import requests\n",
        "from gensim.models import Word2Vec\n",
        "from jamo import h2j, j2hcj\n",
        "from konlpy.tag import Okt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEVZUIalBnN",
        "outputId": "66de70f6-dddf-4909-c5ae-5a64c96e1ff9"
      },
      "source": [
        "# 구글 드라이브 연결\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "path = \"gdrive/My Drive/Colab Notebooks/PMS/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLo7SrakgvbN"
      },
      "source": [
        "# 파일 확장자 및 특수문자 제거 후 형태소 명사 단위로 분석\n",
        "\n",
        "def morpheme(file_name):\n",
        "  okt = Okt()\n",
        "\n",
        "  no_extension_file_name = file_name.rsplit('.', 1)[0] \n",
        "  cleaned_file_name = re.sub('[-=+,_#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]',\n",
        "                             '', no_extension_file_name)\n",
        "\n",
        "  return cleaned_file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt_ze3vbdgha"
      },
      "source": [
        "# 영어 문장 한글로 번역\n",
        "\n",
        "def get_translate_ko(text):\n",
        "    client_id = \"36sG5L0c4JVanssDM_3E\" # <-- client_id 기입\n",
        "    client_secret = \"nJ4nIqNdgh\" # <-- client_secret 기입\n",
        "\n",
        "    data = {'text' : text,\n",
        "            'source' : 'en',\n",
        "            'target': 'ko'}\n",
        "\n",
        "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
        "\n",
        "    header = {\"X-Naver-Client-Id\":client_id,\n",
        "              \"X-Naver-Client-Secret\":client_secret}\n",
        "\n",
        "    response = requests.post(url, headers=header, data=data)\n",
        "    rescode = response.status_code\n",
        "\n",
        "    if(rescode==200):\n",
        "        send_data = response.json()\n",
        "        trans_data = (send_data['message']['result']['translatedText'])\n",
        "        return trans_data\n",
        "    else:\n",
        "        print(\"Error Code:\" , rescode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZCw7uTgRFb"
      },
      "source": [
        "# 한글 문장 영어로 번역\n",
        "\n",
        "def get_translate_eng(text):\n",
        "    client_id = \"fSuwQC7wzKdKWD4f0Gbl\" # <-- client_id 기입\n",
        "    client_secret = \"upCLLCyDRI\" # <-- client_secret 기입\n",
        "\n",
        "    data = {'text' : text,\n",
        "            'source' : 'ko',\n",
        "            'target': 'en'}\n",
        "\n",
        "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
        "\n",
        "    header = {\"X-Naver-Client-Id\":client_id,\n",
        "              \"X-Naver-Client-Secret\":client_secret}\n",
        "\n",
        "    response = requests.post(url, headers=header, data=data)\n",
        "    rescode = response.status_code\n",
        "\n",
        "    if(rescode==200):\n",
        "        send_data = response.json()\n",
        "        trans_data = (send_data['message']['result']['translatedText'])\n",
        "        return trans_data\n",
        "    else:\n",
        "        print(\"Error Code:\" , rescode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n1LHx4PfCOe"
      },
      "source": [
        "# 데이터 전처리 함수\n",
        "\n",
        "def data_preprocess(data_list): # 파일 리스트 / 디렉토리 리스트\n",
        "    preprocessed_list = data_list\n",
        "    tmp_data=\"\"\n",
        "    result = []\n",
        "\n",
        "    # 형태소 분석, 특수기호 제거\n",
        "    for data_index in range(len(preprocessed_list)):\n",
        "        split_data = morpheme(preprocessed_list[data_index])\n",
        "        preprocessed_list[data_index] = split_data\n",
        "    \n",
        "    # 번역 api : 영어 번역, 띄어쓰기\n",
        "    for index in range(len(preprocessed_list)):\n",
        "      # 영어 거쳐서 한국어 번역하면 정확도 높은 대신\n",
        "      # 시간 오래걸리고 api 일일 사용량 제한 더 잘걸림\n",
        "      eng_list = get_translate_eng(preprocessed_list[index])\n",
        "      ko_list = get_translate_ko(eng_list)\n",
        "      # ko_list = get_translate_ko(preprocessed_list[index])\n",
        "      result.append(ko_list)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgdejit3hVvX"
      },
      "source": [
        "# 폴더 안에 들어간 파일들의 내용 저장\n",
        "\n",
        "def save_classificated_file(index_dict, file_list, directory_list):\n",
        "    result_dict = {}\n",
        "\n",
        "    for key, value in index_dict.items():\n",
        "        result_dict[file_list[key]] = directory_list[value]\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhTJyCrIhdfL"
      },
      "source": [
        "# 매칭된 파일 제거\n",
        "\n",
        "def rm_classificated_file(index_dict,file_list):  # 매칭된 파일 제거\n",
        "    data_name = []\n",
        "    for index in list(index_dict.keys()):\n",
        "        data_name.append(file_list[index])\n",
        "\n",
        "    file_list =  [x for x in file_list if x not in (data_name)]\n",
        "\n",
        "    return file_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA1ASd0Fgl6O"
      },
      "source": [
        "# 단순 유사도 검사\n",
        "# 파일명과 카테고리명이 같으면 그 폴더 안에 넣어줌\n",
        "\n",
        "def simplest_classification(directory_list, file_list):  # 단어 유사도 검사 => index return해서 제거하는 방법을 쓴다.\n",
        "    tmp_dict = {}\n",
        "    if jpype.isJVMStarted():\n",
        "      jpype.attachThreadToJVM()\n",
        "    okt = Okt()\n",
        "    classificated_dir_index = 0\n",
        "    for file_index in range(len(file_list)):\n",
        "        file_morphs = okt.morphs(file_list[file_index])\n",
        "        \n",
        "        max_weight = 0\n",
        "        for dir_index in range(len(directory_list)): # 디렉토리 갯수 : 3\n",
        "            dir_morphs = okt.morphs(directory_list[dir_index])\n",
        "            tmp_weight = 0\n",
        "            for file_element in file_morphs: # 형태분석한 파일 갯수\n",
        "                for dir_element in dir_morphs:\n",
        "                    \n",
        "                    if (dir_element == file_element) and (check_format(dir_element) == ('kor')):\n",
        "                        tmp_weight += 2      \n",
        "                    \t#한글로 되있을 경우 가중치 2\n",
        "                    elif ((file_element in dir_element) and (check_format(dir_element) == ('num'))):\n",
        "                        tmp_weight += 1\n",
        "                        #영어로 되있을 경우 가중치 1\n",
        "                        \n",
        "            if (tmp_weight > max_weight):\n",
        "                max_weight = tmp_weight\n",
        "                classificated_dir_index = dir_index\n",
        "        if max_weight > 0:\n",
        "            tmp_dict[file_index] = classificated_dir_index\n",
        "\n",
        "    return tmp_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ2fleL2sRjT"
      },
      "source": [
        "# 한글과 숫자를 판단하고 가중치를 넣어주는 함수\n",
        "# 숫자보다 한글의 가중치가 높게 설정\n",
        "\n",
        "def check_format(input): # 한국어 , 영어 , 숫자 형태 분석\n",
        "    value = input[0]\n",
        "    if ord('가') <= ord(value) <= ord('힣'):\n",
        "        return 'kor'\n",
        "    elif value.isdigit():\n",
        "        return 'num'\n",
        "    elif value.isalpha():\n",
        "        return 'eng'\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyaG8uRiheQy"
      },
      "source": [
        "# Word2Vec 유사도 측정\n",
        "# 제목과 카테고리명 사이의 유사도를 측정, 퍼센테이지 출력\n",
        "\n",
        "def word2vec_similarity(directory_list, file_list):\n",
        "    model = Word2Vec.load(path+'ko.bin')\n",
        "\n",
        "    tmp_dict = {}\n",
        "    classificated_dir_index = 0\n",
        "    if jpype.isJVMStarted():\n",
        "      jpype.attachThreadToJVM()\n",
        "    okt = Okt() # 형태소 분석\n",
        "    for file_index in range(len(file_list)):\n",
        "        max_similarity = 0\n",
        "        file_morphs = okt.morphs(file_list[file_index])\n",
        "        for dir_index in range(len(directory_list)):\n",
        "            dir_morphs = okt.morphs(directory_list[dir_index])\n",
        "            tmp_similarity = 0\n",
        "            for file_element in file_morphs:\n",
        "                for dir_element in dir_morphs:\n",
        "                    if check_format(file_element) == 'kor' and check_format(dir_element) == 'kor':\n",
        "                        try:\n",
        "                            tmp_similarity = model.similarity(file_element, dir_element)\n",
        "                        except KeyError:\n",
        "                            pass\n",
        "                if tmp_similarity > max_similarity:  # 유사도 수치는 사용자가 설정\n",
        "                    max_similarity = tmp_similarity\n",
        "                    classificated_dir_index = dir_index\n",
        "\n",
        "            tmp_dict[file_index] = classificated_dir_index\n",
        "\n",
        "    return tmp_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwsI-_FRhjWM"
      },
      "source": [
        "# 자모 단위를 이용한 유사도 검사\n",
        "\n",
        "def Phonology_classification(directory_list, file_list):\n",
        "    trans_file_jumo = []\n",
        "    trans_folder_jumo = []\n",
        "    equl_count = [[0 for i in range(len(file_list))] for i in range(len(directory_list))]\n",
        "    result_dict = {}\n",
        "\n",
        "    for i in file_list:\n",
        "        a = j2hcj(h2j(i))\n",
        "        line = []\n",
        "        for j in a:\n",
        "            line.append(j2hcj(h2j(j)))\n",
        "        trans_file_jumo.append(line)\n",
        "\n",
        "    for i in directory_list:\n",
        "        a = j2hcj(h2j(i))\n",
        "        line = []\n",
        "        for j in a:\n",
        "            line.append(j2hcj(h2j(j)))\n",
        "        trans_folder_jumo.append(line)\n",
        "\n",
        "    for i in range(len(directory_list)):\n",
        "        for j in range(len(file_list)):\n",
        "            for k in trans_file_jumo[j]:\n",
        "                if k in trans_folder_jumo[i]:\n",
        "                    equl_count[i][j] += 1\n",
        "\n",
        "    for i in range(len(directory_list)):\n",
        "        for j in range(len(file_list)):\n",
        "            if len(trans_folder_jumo[i]) <= equl_count[i][j]:\n",
        "                result_dict[j] = i\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNuf_5keiM4J"
      },
      "source": [
        "def dict_to_list(dict):\n",
        "    result = []\n",
        "\n",
        "    for key, value in dict.items():\n",
        "        tmp = str(value) + \"/\"+ str(key)\n",
        "        result.append(tmp)\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGuxNSyGiHNT"
      },
      "source": [
        "# 기타 폴더\n",
        "# 분류가 안된 파일들을 기타로 분류해줌\n",
        "\n",
        "def except_directory(file_list):\n",
        "    out_of_classification = \"except_directory\"\n",
        "    result_dict = {}\n",
        "\n",
        "    for file in file_list:\n",
        "        result_dict[file] = out_of_classification\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MphdSiPtiOSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ab378c-38d7-40ee-8d5c-8c147a57ec61"
      },
      "source": [
        "# 분류될 카테고리명\n",
        "directory_list = ['영어', '외국어', '국어', '문예', '네이밍', '슬로건', '논문', '수학', '과학', '학습•문예', '코딩', '프로그래밍', '해커톤', '메이커톤', '해킹', '보안', '빅데이터', '인공지능', '사물인터넷', 'IT', '컴퓨터', '달리기', '마라톤', '자전거', '수영', '야구', '축구', '농구', '배구', '배드민턴', '테니스', '골프', '볼링', '당구', '탁구 ', '무예', '레포츠', 'e-스포츠', '스포츠', '그림', '그리기', '디자인', '캐릭터', '웹툰', '공예', '만들기', '미술', '동요', '성악', '실용음악', '가요', '국악', '무용', '발레', '댄스', '배우', '오디션', '음악', '무용', '배우', '사진', 'UCC', '동영상', '드론', '요리', '반려동물', '뷰티', '선발', '주산암산', '바둑', '체스', '건축', '제안', '아이디어', '산업', '사회', '창업', '퀴즈', '이색']\n",
        "# 분류할 문서 이름\n",
        "file_list = []\n",
        "data = pd.read_csv(path+\"data2.csv\", encoding=\"cp949\")\n",
        "for i in range(len(data)):\n",
        "  file_list.append(data['Column1'][i])\n",
        "file_list = file_list[400:430]\n",
        "print(file_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['평택시 신중년의 손 사진 공모전 「인생을 담다」', '2021년도 부산관광공사 시민 아이디어 공모전', '제9회 아름다운 우리 국토 사진공모전', '치매예방 시니어 가요 콩쿨', '제4회 전국 중학생 K-POP 경연대회', '제5회 GO BACK 예산장터 삼국축제 공모전', \"제3회 시민참여 공모전-'쓰.담 공모전' 일터생활 공모전\", '탄소중립 달성을 위한 전력산업 아이디어 발굴 경진대회', '<2021 서점의 날> 지역서점 브이로그 공모전', '2021년 삼각산 동요대회', '2021년 나마스떼코리아 제6회 히말라야 사진(영상) 공모전 [기간연장]', '제주특별자치도 청년 캐릭터 공모전', '2021 전국 학생발명상상화 및 캐릭터 · 디자인 그리기 대회', '2021 군산시 슬기로운 가족생활 사진공모전', '제18회 청소년 봉사활동 실천사례 발표대회', '석유 데이터 활용 아이디어 공모전', '2021 SK하이닉스 기후변화 위기극복 작품공모전', '제12회 통신서비스 이용자주간 통신서비스 피해예방 웹툰공모전', '제1회 수목원·정원 분야 국민참여 아이디어 공모전', '국민안전 119초 영상 공모전', '2022 제주들불축제 콘텐츠 아이디어 공모전', '2021년도 한국기술교육대학교 안전 분야 혁신 아이디어 공모전', '증평인삼문화센터 BI 디자인 공모전', '모인 해외송금 학생 할인 서비스 네이밍 공모전', '필환경 제주관광 슬로건 공모전', '제5회 대학생 통상정책 토론대회', '다문화 이주여성 대상 한국산 임산물 활용 현지 요리 UCC 공모전', '2021 대한민국 교육 공로 표창 행사(공모전)', '청풍아름그린 사진 & 100초영상 공모전', '2021 수출 핫템 공모전']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdv22YdMiYfz"
      },
      "source": [
        "# 제목 기반 자동 분류\n",
        "def title_classification(directory_list, file_list):\n",
        "    result_dict = {}\n",
        "    index_dict = {}\n",
        "\n",
        "    origin_directory_list = directory_list.copy()\n",
        "    origin_file_list = file_list.copy()\n",
        "\n",
        "    # 데이터 전처리\n",
        "    tmp_dir_list = data_preprocess(directory_list)\n",
        "    tmp_file_list = data_preprocess(file_list)\n",
        "\n",
        "    # 단순 유사도 검사\n",
        "    index_dict = simplest_classification(tmp_dir_list, tmp_file_list)\n",
        "    ## update\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # Word2Vec를 이용한 유사도 검사\n",
        "    index_dict = word2vec_similarity(tmp_dir_list, tmp_file_list)\n",
        "    ## update\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # 자모단위 유사도 검사\n",
        "    index_dict = Phonology_classification(tmp_dir_list, tmp_file_list)\n",
        "    ## update\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # 기타 분류\n",
        "    result_dict.update(except_directory(origin_file_list))\n",
        "\n",
        "    result_list = dict_to_list(result_dict)\n",
        "    return result_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWelqjojxvjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23157615-233e-46e9-dab6-e5425707cbac"
      },
      "source": [
        "res = title_classification(directory_list, file_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llGhKy7psmJ4",
        "outputId": "444f1153-3ac4-4035-d26d-abe0d8c7ed7f"
      },
      "source": [
        "for i in res:\n",
        "  print(i, end=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사진/평택시 신중년의 손 사진 공모전 「인생을 담다」\n",
            "아이디어/2021년도 부산관광공사 시민 아이디어 공모전\n",
            "사진/제9회 아름다운 우리 국토 사진공모전\n",
            "가요/제4회 전국 중학생 K-POP 경연대회\n",
            "아이디어/탄소중립 달성을 위한 전력산업 아이디어 발굴 경진대회\n",
            "수영/<2021 서점의 날> 지역서점 브이로그 공모전\n",
            "동요/2021년 삼각산 동요대회\n",
            "사진/2021년 나마스떼코리아 제6회 히말라야 사진(영상) 공모전 [기간연장]\n",
            "캐릭터/제주특별자치도 청년 캐릭터 공모전\n",
            "그리기/2021 전국 학생발명상상화 및 캐릭터 · 디자인 그리기 대회\n",
            "사진/2021 군산시 슬기로운 가족생활 사진공모전\n",
            "아이디어/석유 데이터 활용 아이디어 공모전\n",
            "수영/2021 SK하이닉스 기후변화 위기극복 작품공모전\n",
            "웹툰/제12회 통신서비스 이용자주간 통신서비스 피해예방 웹툰공모전\n",
            "아이디어/제1회 수목원·정원 분야 국민참여 아이디어 공모전\n",
            "아이디어/2022 제주들불축제 콘텐츠 아이디어 공모전\n",
            "아이디어/2021년도 한국기술교육대학교 안전 분야 혁신 아이디어 공모전\n",
            "디자인/증평인삼문화센터 BI 디자인 공모전\n",
            "네이밍/모인 해외송금 학생 할인 서비스 네이밍 공모전\n",
            "슬로건/필환경 제주관광 슬로건 공모전\n",
            "사진/청풍아름그린 사진 & 100초영상 공모전\n",
            "볼링/치매예방 시니어 가요 콩쿨\n",
            "탁구 /제5회 GO BACK 예산장터 삼국축제 공모전\n",
            "탁구 /제3회 시민참여 공모전-'쓰.담 공모전' 일터생활 공모전\n",
            "탁구 /제18회 청소년 봉사활동 실천사례 발표대회\n",
            "사진/국민안전 119초 영상 공모전\n",
            "산업/제5회 대학생 통상정책 토론대회\n",
            "컴퓨터/다문화 이주여성 대상 한국산 임산물 활용 현지 요리 UCC 공모전\n",
            "탁구 /2021 대한민국 교육 공로 표창 행사(공모전)\n",
            "캐릭터/2021 수출 핫템 공모전\n"
          ]
        }
      ]
    }
  ]
}