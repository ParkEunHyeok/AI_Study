{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZHnKKXLzpHAUAtYWDAl6Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkEunHyeok/AI_Study/blob/main/NLP/seq2seq_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9iFvxie1ZjW",
        "outputId": "36d90fc4-d6aa-4ea9-b54d-2bf09dbd3e33"
      },
      "source": [
        "!pip install Korpora\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Korpora\n",
            "  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.46.0\n",
            "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from Korpora) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from Korpora) (1.19.5)\n",
            "Collecting dataclasses>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting xlrd>=1.2.0\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->Korpora) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->Korpora) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->Korpora) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->Korpora) (1.24.3)\n",
            "Installing collected packages: xlrd, tqdm, dataclasses, Korpora\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed Korpora-0.2.0 dataclasses-0.6 tqdm-4.61.2 xlrd-2.0.1\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 60.2 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_52WBlN1EoR",
        "outputId": "e1df80bb-b0ab-4d89-9824-86fc7e76f4cd"
      },
      "source": [
        "# songys 챗봇 데이터 불러오는 korpora 모듈\n",
        "from Korpora import KoreanChatbotKorpus\n",
        "from Korpora import Korpora\n",
        "corpus = KoreanChatbotKorpus()\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from keras import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : songys@github\n",
            "    Repository : https://github.com/songys/Chatbot_data\n",
            "    References :\n",
            "\n",
            "    Chatbot_data_for_Korean v1.0\n",
            "      1. 챗봇 트레이닝용 문답 페어 11,876개\n",
            "      2. 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링\n",
            "    자세한 내용은 위의 repository를 참고하세요.\n",
            "\n",
            "    # License\n",
            "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
            "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[korean_chatbot_data] download ChatbotData.csv: 893kB [00:00, 12.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcuQ2tZ72ktB"
      },
      "source": [
        "# 태그 단어\n",
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
        "\n",
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3\n",
        "\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2\n",
        "\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "\n",
        "# 임베딩 벡터 차원\n",
        "embedding_dim = 100\n",
        "\n",
        "# LSTM 히든레이어 차원\n",
        "lstm_hidden_dim = 128\n",
        "\n",
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxKGH4fu1Xzi",
        "outputId": "f686cfe7-edfc-48eb-d5b1-b3d270ef4b40"
      },
      "source": [
        "# 구어체로 되어 있음.\n",
        "# text와 pair가 쌍으로 이루어짐\n",
        "corpus.get_all_texts()[:5]\n",
        "corpus.get_all_pairs()[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyRIgpYh1tSG",
        "outputId": "e5d4c3d5-4ec2-4f00-9a7c-3fa6e8425bea"
      },
      "source": [
        "question = []\n",
        "answer = []\n",
        "\n",
        "for sentence in corpus.get_all_texts():\n",
        "    question.append(sentence)\n",
        "\n",
        "for sentence in corpus.get_all_pairs():\n",
        "    answer.append(sentence)\n",
        "\n",
        "list(zip(question, answer))[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('12시 땡!', '하루가 또 가네요.'),\n",
              " ('1지망 학교 떨어졌어', '위로해 드립니다.'),\n",
              " ('3박4일 놀러가고 싶다', '여행은 언제나 좋죠.'),\n",
              " ('3박4일 정도 놀러가고 싶다', '여행은 언제나 좋죠.'),\n",
              " ('PPL 심하네', '눈살이 찌푸려지죠.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvJO7pB3bl5"
      },
      "source": [
        "question = question[:3000]\n",
        "answer = answer[:3000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stj06Bvl15JN"
      },
      "source": [
        "# 형태소분석 함수\n",
        "def pos_tag(sentences):\n",
        "    \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    \n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = []\n",
        "    \n",
        "    # 모든 문장 반복\n",
        "    for sentence in sentences:\n",
        "        # 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
        "        \n",
        "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "        \n",
        "    return sentences_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqQ7CyfN2KQk",
        "outputId": "1c6793d7-db72-43da-8db5-5669e2625afa"
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)\n",
        "\n",
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(10):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q : 12시 땡\n",
            "A : 하루 가 또 가네요\n",
            "\n",
            "Q : 1 지망 학교 떨어졌어\n",
            "A : 위로 해 드립니다\n",
            "\n",
            "Q : 3 박 4일 놀러 가고 싶다\n",
            "A : 여행 은 언제나 좋죠\n",
            "\n",
            "Q : 3 박 4일 정도 놀러 가고 싶다\n",
            "A : 여행 은 언제나 좋죠\n",
            "\n",
            "Q : PPL 심하네\n",
            "A : 눈살 이 찌푸려지죠\n",
            "\n",
            "Q : SD 카드 망가졌어\n",
            "A : 다시 새로 사는 게 마음 편해요\n",
            "\n",
            "Q : SD 카드 안 돼\n",
            "A : 다시 새로 사는 게 마음 편해요\n",
            "\n",
            "Q : SNS 맞팔 왜 안 하지 ㅠㅠ\n",
            "A : 잘 모르고 있을 수도 있어요\n",
            "\n",
            "Q : SNS 시간 낭비 인 거 아는데 매일 하는 중\n",
            "A : 시간 을 정 하고 해보세요\n",
            "\n",
            "Q : SNS 시간 낭비 인데 자꾸 보게 됨\n",
            "A : 시간 을 정 하고 해보세요\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88qW_FkF2MkM"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침\n",
        "sentences = []\n",
        "sentences.extend(question)\n",
        "sentences.extend(answer)\n",
        "\n",
        "words = []\n",
        "\n",
        "# 단어들의 배열 생성\n",
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)\n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]\n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n",
        "\n",
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_jrYpyM21cz",
        "outputId": "b25c1e95-4805-4b57-a564-e9106626f548"
      },
      "source": [
        "# 단어 개수\n",
        "len(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anKWNktU25I7",
        "outputId": "ac3d76eb-af84-48e2-979e-8733cb913e28"
      },
      "source": [
        "words[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PADDING>', '<START>', '<END>', '<OOV>', '이어주는', '깍', '캐', '여서', '거둘', '오빠']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elOwGr9p3FP6"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb6TKDA-3ITq",
        "outputId": "adcef487-025b-42af-ea48-9f2daf28fb90"
      },
      "source": [
        "# 단어 -> 인덱스\n",
        "# 문장을 인덱스로 변환하여 모델 입력으로 사용\n",
        "dict(list(word_to_index.items())[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<END>': 2,\n",
              " '<OOV>': 3,\n",
              " '<PADDING>': 0,\n",
              " '<START>': 1,\n",
              " 'SNS': 16,\n",
              " '거둘': 8,\n",
              " '괜찮': 12,\n",
              " '깍': 5,\n",
              " '드립니다': 14,\n",
              " '디저트': 13,\n",
              " '따뜻해졌죠': 19,\n",
              " '맡겨': 11,\n",
              " '배고프다': 18,\n",
              " '선의': 15,\n",
              " '여서': 7,\n",
              " '오는데': 17,\n",
              " '오빠': 9,\n",
              " '이어주는': 4,\n",
              " '주는': 10,\n",
              " '캐': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTmKi-q_3Jab",
        "outputId": "7ea18e4e-25a1-4d20-86cf-6e9a10eca0ec"
      },
      "source": [
        "# 인덱스 -> 단어\n",
        "# 모델의 예측 결과인 인덱스를 문장으로 변환시 사용\n",
        "dict(list(index_to_word.items())[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '<PADDING>',\n",
              " 1: '<START>',\n",
              " 2: '<END>',\n",
              " 3: '<OOV>',\n",
              " 4: '이어주는',\n",
              " 5: '깍',\n",
              " 6: '캐',\n",
              " 7: '여서',\n",
              " 8: '거둘',\n",
              " 9: '오빠',\n",
              " 10: '주는',\n",
              " 11: '맡겨',\n",
              " 12: '괜찮',\n",
              " 13: '디저트',\n",
              " 14: '드립니다',\n",
              " 15: '선의',\n",
              " 16: 'SNS',\n",
              " 17: '오는데',\n",
              " 18: '배고프다',\n",
              " 19: '따뜻해졌죠'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3JPrNQg3LTa"
      },
      "source": [
        "\n",
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    \n",
        "    sentences_index = []\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences:\n",
        "        sentence_index = []\n",
        "        \n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "        \n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split():\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])\n",
        "            else:\n",
        "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "        \n",
        "        # 문장의 인덱스 배열을 추가\n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bGBJVWn3Nm8",
        "outputId": "d16e519b-9f06-4012-8e07-079398fa8a2b"
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "\n",
        "# 첫 번째 인코더 입력 출력 (12시 땡)\n",
        "x_encoder[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1027,  881,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88IOxR4F3O_C",
        "outputId": "d861a456-5ba5-4c7c-f91c-62714abe6937"
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (START 하루 가 또 가네요)\n",
        "x_decoder[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1, 1788,  579,   84, 3962,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUYPNsR53Sfi",
        "outputId": "45b13ca3-b98c-4c50-e59d-3797bcad97ca"
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 목표 출력 (하루 가 또 가네요 END)\n",
        "y_decoder[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1788,  579,   84, 3962,    2,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzOqkJmk3T1U",
        "outputId": "b8b85cf9-f8f2-4f64-d315-821870d8a7d1"
      },
      "source": [
        "# 원핫인코딩 초기화\n",
        "one_hot_data = np.zeros((len(y_decoder), max_sequences, len(words)))\n",
        "\n",
        "# 디코더 목표를 원핫인코딩으로 변환\n",
        "# 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
        "for i, sequence in enumerate(y_decoder):\n",
        "    for j, index in enumerate(sequence):\n",
        "        one_hot_data[i, j, index] = 1\n",
        "\n",
        "# 디코더 목표 설정\n",
        "y_decoder = one_hot_data\n",
        "\n",
        "# 첫 번째 디코더 목표 출력\n",
        "y_decoder[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRBRklZw3U-z",
        "outputId": "d7cd8a5d-e834-492d-e21b-7142679d4d54"
      },
      "source": [
        "#--------------------------------------------\n",
        "# 훈련 모델 인코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "# 임베딩 레이어\n",
        "encoder_outputs = layers.Embedding(len(words), embedding_dim)(encoder_inputs)\n",
        "\n",
        "# return_state가 True면 상태값 리턴\n",
        "# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n",
        "encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n",
        "                                                dropout=0.1,\n",
        "                                                recurrent_dropout=0.5,\n",
        "                                                return_state=True)(encoder_outputs)\n",
        "\n",
        "# 히든 상태와 셀 상태를 하나로 묶음\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------\n",
        "# 훈련 모델 디코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n",
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "# 임베딩 레이어\n",
        "decoder_embedding = layers.Embedding(len(words), embedding_dim)\n",
        "decoder_outputs = decoder_embedding(decoder_inputs)\n",
        "\n",
        "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
        "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
        "decoder_lstm = layers.LSTM(lstm_hidden_dim,\n",
        "                           dropout=0.1,\n",
        "                           recurrent_dropout=0.5,\n",
        "                           return_state=True,\n",
        "                           return_sequences=True)\n",
        "\n",
        "# initial_state를 인코더의 상태로 초기화\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n",
        "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------\n",
        "# 훈련 모델 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 입력과 출력으로 함수형 API 모델 생성\n",
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 학습 방법 설정\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jTq8Sng31ft"
      },
      "source": [
        "#--------------------------------------------\n",
        "#  예측 모델 인코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
        "encoder_model = models.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------------------\n",
        "# 예측 모델 디코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
        "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
        "decoder_state_input_h = layers.Input(shape=(lstm_hidden_dim,))\n",
        "decoder_state_input_c = layers.Input(shape=(lstm_hidden_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n",
        "\n",
        "# 임베딩 레이어\n",
        "decoder_outputs = decoder_embedding(decoder_inputs)\n",
        "\n",
        "# LSTM 레이어\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n",
        "                                                 initial_state=decoder_states_inputs)\n",
        "\n",
        "# 히든 상태와 셀 상태를 하나로 묶음\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 예측 모델 디코더 설정\n",
        "decoder_model = models.Model([decoder_inputs] + decoder_states_inputs,\n",
        "                      [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QKwIN8S33vb"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "kWmQ70rG35xM",
        "outputId": "4de110e2-e39a-4810-c4cc-56c5c367bd60"
      },
      "source": [
        "# 에폭 반복\n",
        "for epoch in range(1):\n",
        "    print('Total Epoch :', epoch + 1)\n",
        "\n",
        "    # 훈련 시작\n",
        "    history = model.fit([x_encoder, x_decoder],\n",
        "                        y_decoder,\n",
        "                        epochs=10,\n",
        "                        batch_size=64,\n",
        "                        verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Epoch : 1\n",
            "Epoch 1/10\n",
            "47/47 [==============================] - 12s 246ms/step - loss: 0.8405 - accuracy: 0.8564\n",
            "Epoch 2/10\n",
            "29/47 [=================>............] - ETA: 4s - loss: 0.8290 - accuracy: 0.8567"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8cb31f1c5dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO1HGznj1Pvb"
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIOJeVz737Vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5838e57-1f57-46ee-e537-9928d7f541a8"
      },
      "source": [
        "    \n",
        "# 정확도와 손실 출력\n",
        "print('accuracy :', history.history['accuracy'][-1])\n",
        "print('loss :', history.history['loss'][-1])\n",
        "\n",
        "# 문장 예측 테스트\n",
        "# (3 박 4일 놀러 가고 싶다) -> (여행 은 언제나 좋죠)\n",
        "input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n",
        "input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n",
        "results = model.predict([input_encoder, input_decoder])\n",
        "\n",
        "# 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "# 1축을 기준으로 가장 높은 값의 위치를 구함\n",
        "indexs = np.argmax(results[0], 1) \n",
        "\n",
        "# 인덱스를 문장으로 변환\n",
        "sentence = convert_index_to_text(indexs, index_to_word)\n",
        "print(sentence)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.8551777601242065\n",
            "loss : 0.855243980884552\n",
            "저 도 더 해보세요 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}