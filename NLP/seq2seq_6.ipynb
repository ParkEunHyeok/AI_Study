{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0UL7nYvBxxim1hCHVNDu+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkEunHyeok/AI_Study/blob/main/NLP/seq2seq_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jth8ducV8R8",
        "outputId": "ec0765c4-40d3-4996-c5dc-89ffb53c12e6"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uWxf1hnWU6g"
      },
      "source": [
        "# regex expression 적용하는 모듈\n",
        "import re\n",
        "\n",
        "# konlpy 형태소 분석기 사용하여 형태소 분석\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "# Tokenize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# One Hot Encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# seq2seq Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# WARNING 무시\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPpqmCBv99Sb",
        "outputId": "e407fcd1-5264-4466-be99-ac5fb8f656e1"
      },
      "source": [
        "# 구글 드라이브 연결\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "path = \"gdrive/My Drive/Colab Notebooks/seq2seq\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeX6vUHtm8TI"
      },
      "source": [
        "wellness = pd.read_csv(\"gdrive/My Drive/Colab Notebooks/HelloNewWorld/wellnessData.csv\")\n",
        "songys = pd.read_csv(\"gdrive/My Drive/Colab Notebooks/HelloNewWorld/songysData.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "mUf56ndSm9h9",
        "outputId": "7c614930-acbc-4536-8e39-5270a9b46904"
      },
      "source": [
        "# 결측 row 제거하는 방법, 5232개\n",
        "wellness.dropna(how='any')\n",
        "wellness[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>구분</th>\n",
              "      <th>유저</th>\n",
              "      <th>챗봇</th>\n",
              "      <th>라벨</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>제 감정이 이상해진 것 같아요. 남편만 보면 화가 치밀어 오르고 감정 조절이 안되요.</td>\n",
              "      <td>감정이 조절이 안 될 때만큼 힘들 때는 없는 거 같아요.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>더 이상 내 감정을 내가 컨트롤 못 하겠어.</td>\n",
              "      <td>저도 그 기분 이해해요. 많이 힘드시죠?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>하루종일 오르락내리락 롤러코스터 타는 기분이에요.</td>\n",
              "      <td>그럴 때는 밥은 잘 먹었는지, 잠은 잘 잤는지 체크해보는 것도 좋아요.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>꼭 롤러코스터 타는 것 같아요.</td>\n",
              "      <td>그럴 때 마음을 편하게 가지고, 기분 좋은 생각을 한번 해보는건 어떨까요.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>롤러코스터 타는 것처럼 기분이 왔다 갔다 해요.</td>\n",
              "      <td>저도 그 기분 이해해요. 많이 힘드시죠?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>작년 가을부터 감정조절이 잘 안 되는 거 같아.</td>\n",
              "      <td>그럴 때 마음을 편하게 가지고, 기분 좋은 생각을 한번 해보는건 어떨까요.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>예전에 비해서 인내심이 너무 짧아진 거 같아.</td>\n",
              "      <td>요즈음 힘든 일이 많으신가봐요.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>더 이상 혼자서는 감정조절을 못하겠어.</td>\n",
              "      <td>그럴 때는 어디에 털어놓아 보는건 어떨까요.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>점점 나 자신을 컨트롤하지 못하는 기분이야.</td>\n",
              "      <td>그럴 때는 어디에 털어놓아 보는건 어떨까요.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>감정/감정조절이상</td>\n",
              "      <td>나도 이러기 싫은데 내 마음대로 안돼.</td>\n",
              "      <td>저도 그 기분 이해해요. 많이 힘드시죠?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          구분  ...   라벨\n",
              "0  감정/감정조절이상  ...  0.0\n",
              "1  감정/감정조절이상  ...  0.0\n",
              "2  감정/감정조절이상  ...  0.0\n",
              "3  감정/감정조절이상  ...  0.0\n",
              "4  감정/감정조절이상  ...  0.0\n",
              "5  감정/감정조절이상  ...  0.0\n",
              "6  감정/감정조절이상  ...  0.0\n",
              "7  감정/감정조절이상  ...  0.0\n",
              "8  감정/감정조절이상  ...  0.0\n",
              "9  감정/감정조절이상  ...  0.0\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vftfYZiMWeJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed6e564-6668-4558-bd54-05e6955a9548"
      },
      "source": [
        "texts = []\n",
        "pairs = []\n",
        "\n",
        "for sentence in wellness['유저']:\n",
        "    texts.append(sentence)\n",
        "\n",
        "for sentence in wellness['챗봇']:\n",
        "    pairs.append(sentence)\n",
        "\n",
        "list(zip(texts, pairs))[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('제 감정이 이상해진 것 같아요. 남편만 보면 화가 치밀어 오르고 감정 조절이 안되요.',\n",
              "  '감정이 조절이 안 될 때만큼 힘들 때는 없는 거 같아요.'),\n",
              " ('더 이상 내 감정을 내가 컨트롤 못 하겠어.', '저도 그 기분 이해해요. 많이 힘드시죠?'),\n",
              " ('하루종일 오르락내리락 롤러코스터 타는 기분이에요.', '그럴 때는 밥은 잘 먹었는지, 잠은 잘 잤는지 체크해보는 것도 좋아요.'),\n",
              " ('꼭 롤러코스터 타는 것 같아요.', '그럴 때 마음을 편하게 가지고, 기분 좋은 생각을 한번 해보는건 어떨까요.'),\n",
              " ('롤러코스터 타는 것처럼 기분이 왔다 갔다 해요.', '저도 그 기분 이해해요. 많이 힘드시죠?')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dBCfXec5boz"
      },
      "source": [
        "# 램이 부족한 관계로 3000개만 학습함\n",
        "texts = texts[:3000]\n",
        "pairs = pairs[:3000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Svoo8q6KYKvX",
        "outputId": "87df3fc2-61c7-4722-ca63-775ad66f9ae1"
      },
      "source": [
        "def clean_sentence(sentence):\n",
        "    # 한글, 숫자를 제외한 모든 문자 제거\n",
        "    sentence = re.sub(r'[^0-9ㄱ-ㅎㅏ-ㅣ가-힣 ]',r'', sentence)\n",
        "    return sentence\n",
        "  \n",
        "clean_sentence('abcef가나다^^$%@12시 땡^^!??')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'가나다12시 땡'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpL04PHEYXAv"
      },
      "source": [
        "okt = Okt()\n",
        "\n",
        "# 형태소 변환해주는 함수\n",
        "# morphs 함수 안에 변환한 한글 문장 입력\n",
        "def process_morph(sentence):\n",
        "    return ' '.join(okt.morphs(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eaRWyF_ZAnW"
      },
      "source": [
        "def clean_and_morph(sentence, is_question=True):\n",
        "    sentence = clean_sentence(sentence)\n",
        "    sentence = process_morph(sentence)\n",
        "    # Question 인 경우, Answer인 경우를 분기\n",
        "    if is_question:\n",
        "        return sentence\n",
        "    else:\n",
        "        # START 토큰 : decoder input, END 토큰 : decoder output\n",
        "        return ('<START> ' + sentence, sentence + ' <END>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWtKkdbpZf11"
      },
      "source": [
        "def preprocess(texts, pairs):\n",
        "    questions = []\n",
        "    answer_in = []\n",
        "    answer_out = []\n",
        "\n",
        "    # Question 전처리\n",
        "    for text in texts:\n",
        "        # 전처리와 morph 수행\n",
        "        question = clean_and_morph(text, is_question=True)\n",
        "        questions.append(question)\n",
        "\n",
        "    # Answer 전처리\n",
        "    for pair in pairs:\n",
        "        # 전처리와 morph 수행\n",
        "        in_, out_ = clean_and_morph(pair, is_question=False)\n",
        "        answer_in.append(in_)\n",
        "        answer_out.append(out_)\n",
        "    \n",
        "    return questions, answer_in, answer_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqoBddTRZjwG"
      },
      "source": [
        "questions, answer_in, answer_out = preprocess(texts, pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dlwm_GIYZlQb",
        "outputId": "f89e420d-27c2-4488-dcb9-ef5e519e47fd"
      },
      "source": [
        "questions[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['제 감정 이 이상해진 것 같아요 남편 만 보면 화가 치밀어 오르고 감정 조절 이 안되요',\n",
              " '더 이상 내 감정 을 내 가 컨트롤 못 하겠어',\n",
              " '하루 종일 오르락내리락 롤러코스터 타는 기분 이에요',\n",
              " '꼭 롤러코스터 타는 것 같아요',\n",
              " '롤러코스터 타는 것 처럼 기분 이 왔다 갔다 해 요']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS1UmOS6ZvRV",
        "outputId": "a0d27b40-85d7-40f5-c921-bccb9198e8a6"
      },
      "source": [
        "answer_out[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['감정 이 조절 이 안 될 때 만큼 힘들 때 는 없는 거 같아요 <END>',\n",
              " '저 도 그 기분 이해해 요 많이 힘드시죠 <END>',\n",
              " '그럴 때 는 밥 은 잘 먹었는지 잠 은 잘 잤는지 체크 해보는 것 도 좋아요 <END>',\n",
              " '그럴 때 마음 을 편하게 가지 고 기분 좋은 생각 을 한번 해보는건 어떨까 요 <END>',\n",
              " '저 도 그 기분 이해해 요 많이 힘드시죠 <END>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igCDhK7vZvpK"
      },
      "source": [
        "all_sentences = questions + answer_in + answer_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESZhf3bzZxCD",
        "outputId": "1182feb4-e32b-43b6-b099-6d04450b5869"
      },
      "source": [
        "a = (' '.join(questions) + ' '.join(answer_in) + ' '.join(answer_out)).split()\n",
        "len(set(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6866"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyUFOyxnZyMq"
      },
      "source": [
        "# Tokenizer 정의\n",
        "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')\n",
        "\n",
        "# Word Index Vocabulary 만들기\n",
        "tokenizer.fit_on_texts(all_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBJ3QHNdZ597",
        "outputId": "319d178c-f8fc-40b6-a3d7-222c47639db2"
      },
      "source": [
        "for word, idx in tokenizer.word_index.items():\n",
        "    print(f'{word}\\t\\t => \\t{idx}')\n",
        "    if idx > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<OOV>\t\t => \t1\n",
            "이\t\t => \t2\n",
            "<START>\t\t => \t3\n",
            "<END>\t\t => \t4\n",
            "을\t\t => \t5\n",
            "가\t\t => \t6\n",
            "도\t\t => \t7\n",
            "것\t\t => \t8\n",
            "요\t\t => \t9\n",
            "은\t\t => \t10\n",
            "에\t\t => \t11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2zGPoYPafbw",
        "outputId": "38088a42-af9c-4786-8370-aa8d770016fc"
      },
      "source": [
        "# 토큰 개수 확인\n",
        "len(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yuryypunai_7"
      },
      "source": [
        "# Text To Sequence Encoding\n",
        "question_sequence = tokenizer.texts_to_sequences(questions)\n",
        "answer_in_sequence = tokenizer.texts_to_sequences(answer_in)\n",
        "answer_out_sequence = tokenizer.texts_to_sequences(answer_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jppwtzeak1P"
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "answer_in_padded = pad_sequences(answer_in_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "answer_out_padded = pad_sequences(answer_out_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlEMNGkUa4i_",
        "outputId": "71db7c12-083d-4883-8d58-af96b1e6685a"
      },
      "source": [
        "print(question_padded.shape)\n",
        "print(answer_in_padded.shape, answer_out_padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 20)\n",
            "(3000, 20) (3000, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECWynjWZa-Zu"
      },
      "source": [
        "# Encoder\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps, name='Embedding')\n",
        "        self.dropout = Dropout(0.3, name='Dropout')\n",
        "        # (attention) return_sequences=True 추가\n",
        "        self.lstm = LSTM(units, return_state=True, return_sequences=True, name='LSTM')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x)\n",
        "        # (attention) x return 추가\n",
        "        return x, [hidden_state, cell_state]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVtdEMoDbPp2"
      },
      "source": [
        "# Decoder\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps, name='Embedding')\n",
        "        self.dropout = Dropout(0.3, name='Dropout')\n",
        "        self.lstm = LSTM(units, \n",
        "                         return_state=True, \n",
        "                         return_sequences=True, \n",
        "                         name='LSTM'\n",
        "                        )\n",
        "        self.attention = Attention(name='Attention')\n",
        "        self.dense = Dense(VOCAB_SIZE, activation='softmax', name='Dense')\n",
        "    \n",
        "    def call(self, inputs, initial_state):\n",
        "        # (attention) encoder_inputs 추가\n",
        "        encoder_inputs, decoder_inputs = inputs\n",
        "        x = self.embedding(decoder_inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x, initial_state=initial_state)\n",
        "        \n",
        "        # (attention) key_value, attention_matrix 추가\n",
        "        # 이전 hidden_state의 값을 concat으로 만들어 vector를 생성합니다.        \n",
        "        key_value = tf.concat([initial_state[0][:, tf.newaxis, :], x[:, :-1, :]], axis=1)        \n",
        "        # 이전 hidden_state의 값을 concat으로 만든 vector와 encoder에서 나온 출력 값들로 attention을 구합니다.\n",
        "        attention_matrix = self.attention([key_value, encoder_inputs])\n",
        "        # 위에서 구한 attention_matrix와 decoder의 출력 값을 concat 합니다.\n",
        "        x = tf.concat([x, attention_matrix], axis=-1)\n",
        "        \n",
        "        x = self.dense(x)\n",
        "        return x, hidden_state, cell_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvW6qXfAbblk"
      },
      "source": [
        "# seq2seq 모델\n",
        "class Seq2Seq(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps, start_token, end_token):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.start_token = start_token\n",
        "        self.end_token = end_token\n",
        "        self.time_steps = time_steps\n",
        "        \n",
        "        self.encoder = Encoder(units, vocab_size, embedding_dim, time_steps)\n",
        "        self.decoder = Decoder(units, vocab_size, embedding_dim, time_steps)\n",
        "        \n",
        "        \n",
        "    def call(self, inputs, training=True):\n",
        "        if training:\n",
        "            encoder_inputs, decoder_inputs = inputs\n",
        "            # (attention) encoder 출력 값 수정\n",
        "            encoder_outputs, context_vector = self.encoder(encoder_inputs)\n",
        "            # (attention) decoder 입력 값 수정\n",
        "            decoder_outputs, _, _ = self.decoder((encoder_outputs, decoder_inputs), initial_state=context_vector)\n",
        "            return decoder_outputs\n",
        "        else:\n",
        "            x = inputs\n",
        "            # (attention) encoder 출력 값 수정\n",
        "            encoder_outputs, context_vector = self.encoder(x)\n",
        "            target_seq = tf.constant([[self.start_token]], dtype=tf.float32)\n",
        "            results = tf.TensorArray(tf.int32, self.time_steps)\n",
        "            \n",
        "            for i in tf.range(self.time_steps):\n",
        "                decoder_output, decoder_hidden, decoder_cell = self.decoder((encoder_outputs, target_seq), initial_state=context_vector)\n",
        "                decoder_output = tf.cast(tf.argmax(decoder_output, axis=-1), dtype=tf.int32)\n",
        "                decoder_output = tf.reshape(decoder_output, shape=(1, 1))\n",
        "                results = results.write(i, decoder_output)\n",
        "                \n",
        "                if decoder_output == self.end_token:\n",
        "                    break\n",
        "                    \n",
        "                target_seq = decoder_output\n",
        "                context_vector = [decoder_hidden, decoder_cell]\n",
        "                \n",
        "            return tf.reshape(results.stack(), shape=(1, self.time_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk6_iXZpblHE"
      },
      "source": [
        "# 단어 별 One-Hot Encoding\n",
        "# answer를 인코딩함\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
        "\n",
        "def convert_to_one_hot(padded):\n",
        "    # 원핫인코딩 초기화\n",
        "    one_hot_vector = np.zeros((len(answer_out_padded), MAX_LENGTH, VOCAB_SIZE))\n",
        "\n",
        "    # 디코더 목표를 원핫인코딩으로 변환\n",
        "    # 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
        "    for i, sequence in enumerate(answer_out_padded):\n",
        "        for j, index in enumerate(sequence):\n",
        "            one_hot_vector[i, j, index] = 1\n",
        "\n",
        "    return one_hot_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YMFc7ap45Co"
      },
      "source": [
        "answer_in_one_hot = convert_to_one_hot(answer_in_padded)\n",
        "answer_out_one_hot = convert_to_one_hot(answer_out_padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TayM3nxY46tP",
        "outputId": "0f0c5b28-e041-4ac9-a225-d14b25957eb8"
      },
      "source": [
        "answer_in_one_hot[0].shape, answer_in_one_hot[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20, 6866), (20, 6866))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qnanGpMbvCF"
      },
      "source": [
        "# sequence to index\n",
        "def convert_index_to_text(indexs, end_token): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == end_token:\n",
        "            # 끝 단어이므로 예측 중비\n",
        "            break;\n",
        "        # 사전에 존재하는 단어의 경우 단어 추가\n",
        "        if index > 0 and tokenizer.index_word[index] is not None:\n",
        "            sentence += tokenizer.index_word[index]\n",
        "        else:\n",
        "        # 사전에 없는 인덱스면 빈 문자열 추가\n",
        "            sentence += ''\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgt7IXrAbw8-"
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 100\n",
        "TIME_STEPS = MAX_LENGTH\n",
        "START_TOKEN = tokenizer.word_index['<START>']\n",
        "END_TOKEN = tokenizer.word_index['<END>']\n",
        "\n",
        "UNITS = 128\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index)+1\n",
        "DATA_LENGTH = len(questions)\n",
        "SAMPLE_SIZE = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4_HYEGtbzEE"
      },
      "source": [
        "# 모델 분산 학습 할 때 체크포인트 저장\n",
        "checkpoint_path = 'gdrive/My Drive/Colab Notebooks/seq2seq/training_checkpoint-6.ckpt'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True,\n",
        "                             save_best_only=True, \n",
        "                             monitor='loss', \n",
        "                             verbose=1\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnH95S6lb4eP",
        "outputId": "b04ba0d1-acbf-4b74-b345-bd3986c55592"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il3o-PY9b6RE",
        "outputId": "7481e5b6-ae67-4717-93db-d37a5444b451"
      },
      "source": [
        "strategy.num_replicas_in_sync"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcAwutUVb8jA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a62e404-a056-4e21-f5a1-68063e446def"
      },
      "source": [
        "# 분산 환경 적용시\n",
        "with strategy.scope():\n",
        "    seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
        "    seq2seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TilMDNVJb-Ez"
      },
      "source": [
        "seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
        "seq2seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVHUJ9ExcFLz"
      },
      "source": [
        "# 연속하여 학습시 체크포인트를 로드하여 이어서 학습합니다.\n",
        "#seq2seq.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3hB6UmdcJJH"
      },
      "source": [
        "def make_prediction(model, question_inputs):\n",
        "    results = model(inputs=question_inputs, training=False)\n",
        "    # 변환된 인덱스를 문장으로 변환\n",
        "    results = np.asarray(results).reshape(-1)\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOUY746JcJgk",
        "outputId": "10f5346d-08f0-4b03-a1c9-9c4043646e3d"
      },
      "source": [
        "# seq2seq 모델 학습\n",
        "for epoch in range(10):\n",
        "    seq2seq.fit([question_padded, answer_in_padded],\n",
        "                answer_out_one_hot,\n",
        "                epochs=10,\n",
        "                batch_size=16, \n",
        "                callbacks=[checkpoint]\n",
        "               )\n",
        "    # 랜덤한 샘플 번호 추출\n",
        "    samples = np.random.randint(DATA_LENGTH, size=SAMPLE_SIZE)\n",
        "\n",
        "    # 예측 성능 테스트\n",
        "    for idx in samples:\n",
        "        question_inputs = question_padded[idx]\n",
        "        # 문장 예측\n",
        "        results = make_prediction(seq2seq, np.expand_dims(question_inputs, 0))\n",
        "        \n",
        "        # 변환된 인덱스를 문장으로 변환\n",
        "        results = convert_index_to_text(results, END_TOKEN)\n",
        "        \n",
        "        print(f'Q: {questions[idx]}')\n",
        "        print(f'A: {results}\\n')\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01XVW1Lkw8oM"
      },
      "source": [
        "# 랜덤한 샘플 번호 추출\n",
        "samples = np.random.randint(DATA_LENGTH, size=SAMPLE_SIZE)\n",
        "\n",
        "# 예측 성능 테스트\n",
        "for idx in samples:\n",
        "    question_inputs = question_padded[idx]\n",
        "    # 문장 예측\n",
        "    results = make_prediction(seq2seq, np.expand_dims(question_inputs, 0))\n",
        "    \n",
        "    # 변환된 인덱스를 문장으로 변환\n",
        "    results = convert_index_to_text(results, END_TOKEN)\n",
        "    \n",
        "    print(f'Q: {questions[idx]}')\n",
        "    print(f'A: {results}\\n')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG2o8kkA0AaW"
      },
      "source": [
        "seq2seq.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4OaiN4cwvJF"
      },
      "source": [
        "seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
        "#tf.keras.models.save_model(seq2seq,'gdrive/My Drive/Colab Notebooks/seq2seq/seq2seq_model.h5')\n",
        "seq2seq.save('gdrive/My Drive/Colab Notebooks/seq2seq/seq2seq_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTVzLPsWcLBI"
      },
      "source": [
        "# 자연어 (질문 입력) 대한 전처리 함수\n",
        "def make_question(sentence):\n",
        "    sentence = clean_and_morph(sentence)\n",
        "    question_sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "    return question_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coYq1uyXcMte"
      },
      "source": [
        "make_question('오늘 날씨가 정말 화창합니다')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b8abwQccOUK"
      },
      "source": [
        "# 챗봇 테스트, 입력받으면 전처리함\n",
        "def run_chatbot(question):\n",
        "    question_inputs = make_question(question)\n",
        "    results = make_prediction(seq2seq, question_inputs)\n",
        "    results = convert_index_to_text(results, END_TOKEN)\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gqaM5facdZX"
      },
      "source": [
        "# 사용자 테스트\n",
        "while True:\n",
        "    user_input = input('<< 말을 걸어 보세요!\\n')\n",
        "    if user_input == 'q':\n",
        "        break\n",
        "    print('>> 챗봇 응답: {}'.format(run_chatbot(user_input)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}