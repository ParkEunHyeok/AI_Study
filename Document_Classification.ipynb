{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Document_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/HiERSXt2jDBCz+s+KSTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkEunHyeok/AI_Study/blob/main/Document_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcgLNnIwgaCD",
        "outputId": "67ace5e8-83aa-4949-eeab-c17471c8de34"
      },
      "source": [
        "!pip3 install konlpy\n",
        "!pip3 install jamo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Using cached konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Using cached JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Using cached beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting colorama\n",
            "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.7/dist-packages (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCWchEWaffI9"
      },
      "source": [
        "import requests # 파파고 번역 api 사용\n",
        "import re\n",
        "import jpype\n",
        "import requests\n",
        "from gensim.models import Word2Vec\n",
        "from jamo import h2j, j2hcj\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEVZUIalBnN",
        "outputId": "d9cd5a94-a70e-4442-8b31-4bbe6914cfca"
      },
      "source": [
        "# 구글 드라이브 연결\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "path = \"gdrive/My Drive/Colab Notebooks/PMS/\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLo7SrakgvbN"
      },
      "source": [
        "def morpheme(file_name): # 파일 확장자 및 특수문자 제거 후 형태소 명사 단위로 분석\n",
        "  okt = Okt()\n",
        "\n",
        "  no_extension_file_name = file_name.rsplit('.', 1)[0] \n",
        "  cleaned_file_name = re.sub('[-=+,_#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', no_extension_file_name)\n",
        "\n",
        "  return cleaned_file_name"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt_ze3vbdgha"
      },
      "source": [
        "def get_translate_ko(text):\n",
        "    client_id = \"fSuwQC7wzKdKWD4f0Gbl\" # <-- client_id 기입\n",
        "    client_secret = \"upCLLCyDRI\" # <-- client_secret 기입\n",
        "\n",
        "    data = {'text' : text,\n",
        "            'source' : 'en',\n",
        "            'target': 'ko'}\n",
        "\n",
        "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
        "\n",
        "    header = {\"X-Naver-Client-Id\":client_id,\n",
        "              \"X-Naver-Client-Secret\":client_secret}\n",
        "\n",
        "    response = requests.post(url, headers=header, data=data)\n",
        "    rescode = response.status_code\n",
        "\n",
        "    if(rescode==200):\n",
        "        send_data = response.json()\n",
        "        trans_data = (send_data['message']['result']['translatedText'])\n",
        "        return trans_data\n",
        "    else:\n",
        "        print(\"Error Code:\" , rescode)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZCw7uTgRFb"
      },
      "source": [
        "def get_translate_eng(text):\n",
        "    client_id = \"fSuwQC7wzKdKWD4f0Gbl\" # <-- client_id 기입\n",
        "    client_secret = \"upCLLCyDRI\" # <-- client_secret 기입\n",
        "\n",
        "    data = {'text' : text,\n",
        "            'source' : 'ko',\n",
        "            'target': 'en'}\n",
        "\n",
        "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
        "\n",
        "    header = {\"X-Naver-Client-Id\":client_id,\n",
        "              \"X-Naver-Client-Secret\":client_secret}\n",
        "\n",
        "    response = requests.post(url, headers=header, data=data)\n",
        "    rescode = response.status_code\n",
        "\n",
        "    if(rescode==200):\n",
        "        send_data = response.json()\n",
        "        trans_data = (send_data['message']['result']['translatedText'])\n",
        "        return trans_data\n",
        "    else:\n",
        "        print(\"Error Code:\" , rescode)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n1LHx4PfCOe"
      },
      "source": [
        "# 데이터 전처리\n",
        "\n",
        "def data_preprocess(data_list): # 파일 리스트 / 디렉토리 리스트 내의 각 명칭에 대한 확장자 제거 및 영어 번역\n",
        "    preprocessed_list = data_list\n",
        "    tmp_data=\"\"\n",
        "    result = []\n",
        "    for data_index in range(len(preprocessed_list)):\n",
        "        split_data = morpheme(preprocessed_list[data_index])\n",
        "        preprocessed_list[data_index] = split_data\n",
        "\n",
        "    for index in range(len(preprocessed_list)):\n",
        "      eng_list = get_translate_eng(preprocessed_list[index])\n",
        "      ko_list = get_translate_ko(eng_list)\n",
        "      result.append(ko_list)\n",
        "    return result"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgdejit3hVvX"
      },
      "source": [
        "def save_classificated_file(index_dict, file_list, directory_list):\n",
        "    result_dict = {}\n",
        "\n",
        "    for key, value in index_dict.items():\n",
        "        result_dict[file_list[key]] = directory_list[value]\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhTJyCrIhdfL"
      },
      "source": [
        "def rm_classificated_file(index_dict,file_list):  # 매칭된 파일 제거\n",
        "    data_name = []\n",
        "    for index in list(index_dict.keys()):\n",
        "        data_name.append(file_list[index])\n",
        "\n",
        "    file_list =  [x for x in file_list if x not in (data_name)]\n",
        "\n",
        "    return file_list"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA1ASd0Fgl6O"
      },
      "source": [
        "# 단순 유사도 검사\n",
        "\n",
        "def simplest_classification(directory_list, file_list):  # 단어 유사도 검사 => index return해서 제거하는 방법을 쓴다.\n",
        "    tmp_dict = {}\n",
        "    if jpype.isJVMStarted():\n",
        "      jpype.attachThreadToJVM()\n",
        "    okt = Okt()\n",
        "    classificated_dir_index = 0\n",
        "    for file_index in range(len(file_list)):\n",
        "        file_morphs = okt.morphs(file_list[file_index])\n",
        "        \n",
        "        max_weight = 0\n",
        "        for dir_index in range(len(directory_list)): # 디렉토리 갯수 : 3\n",
        "            dir_morphs = okt.morphs(directory_list[dir_index])\n",
        "            tmp_weight = 0\n",
        "            for file_element in file_morphs: # 형태분석한 파일 갯수\n",
        "                for dir_element in dir_morphs:\n",
        "                    \n",
        "                    if (dir_element == file_element) and (check_format(dir_element) == ('kor')):\n",
        "                        tmp_weight += 2      \n",
        "                    \t#한글로 되있을 경우 가중치 2\n",
        "                    elif ((file_element in dir_element) and (check_format(dir_element) == ('num'))):\n",
        "                        tmp_weight += 1\n",
        "                        #영어로 되있을 경우 가중치 1\n",
        "                        \n",
        "            if (tmp_weight > max_weight):\n",
        "                max_weight = tmp_weight\n",
        "                classificated_dir_index = dir_index\n",
        "        if max_weight > 0:\n",
        "            tmp_dict[file_index] = classificated_dir_index\n",
        "\n",
        "    return tmp_dict"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ2fleL2sRjT"
      },
      "source": [
        "def check_format(input): # 한국어 , 영어 , 숫자 형태 분석\n",
        "    value = input[0]\n",
        "    if ord('가') <= ord(value) <= ord('힣'):\n",
        "        return 'kor'\n",
        "    elif value.isdigit():\n",
        "        return 'num'\n",
        "    elif value.isalpha():\n",
        "        return 'eng'\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyaG8uRiheQy"
      },
      "source": [
        "def word2vec_similarity(directory_list, file_list):\n",
        "    model = Word2Vec.load(path+'ko.bin')\n",
        "\n",
        "    tmp_dict = {}\n",
        "    classificated_dir_index = 0\n",
        "    if jpype.isJVMStarted():\n",
        "      jpype.attachThreadToJVM()\n",
        "    okt = Okt() # 형태소 분석\n",
        "    for file_index in range(len(file_list)):\n",
        "        max_similarity = 0\n",
        "        file_morphs = okt.morphs(file_list[file_index])\n",
        "        for dir_index in range(len(directory_list)):\n",
        "            dir_morphs = okt.morphs(directory_list[dir_index])\n",
        "            tmp_similarity = 0\n",
        "            for file_element in file_morphs:\n",
        "                for dir_element in dir_morphs:\n",
        "                    if check_format(file_element) == 'kor' and check_format(dir_element) == 'kor':\n",
        "                        try:\n",
        "                            tmp_similarity = model.similarity(file_element, dir_element)\n",
        "                        except KeyError:\n",
        "                            pass\n",
        "                if tmp_similarity > max_similarity:  # 유사도 수치는 사용자가 설정\n",
        "                    max_similarity = tmp_similarity\n",
        "                    classificated_dir_index = dir_index\n",
        "\n",
        "            tmp_dict[file_index] = classificated_dir_index\n",
        "\n",
        "    return tmp_dict"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwsI-_FRhjWM"
      },
      "source": [
        "# 자모 단위를 이용한 유사도 검사\n",
        "\n",
        "def Phonology_classification(directory_list, file_list):\n",
        "    trans_file_jumo = []\n",
        "    trans_folder_jumo = []\n",
        "    equl_count = [[0 for i in range(len(file_list))] for i in range(len(directory_list))]\n",
        "    result_dict = {}\n",
        "\n",
        "    for i in file_list:\n",
        "        a = j2hcj(h2j(i))\n",
        "        line = []\n",
        "        for j in a:\n",
        "            line.append(j2hcj(h2j(j)))\n",
        "        trans_file_jumo.append(line)\n",
        "\n",
        "    for i in directory_list:\n",
        "        a = j2hcj(h2j(i))\n",
        "        line = []\n",
        "        for j in a:\n",
        "            line.append(j2hcj(h2j(j)))\n",
        "        trans_folder_jumo.append(line)\n",
        "\n",
        "    for i in range(len(directory_list)):\n",
        "        for j in range(len(file_list)):\n",
        "            for k in trans_file_jumo[j]:\n",
        "                if k in trans_folder_jumo[i]:\n",
        "                    equl_count[i][j] += 1\n",
        "\n",
        "    for i in range(len(directory_list)):\n",
        "        for j in range(len(file_list)):\n",
        "            if len(trans_folder_jumo[i]) <= equl_count[i][j]:\n",
        "                result_dict[j] = i\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNuf_5keiM4J"
      },
      "source": [
        "def dict_to_list(dict):\n",
        "    result = []\n",
        "\n",
        "    for key, value in dict.items():\n",
        "        tmp = str(value) + \"/\"+ str(key)\n",
        "        result.append(tmp)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGuxNSyGiHNT"
      },
      "source": [
        "# 기타 폴더\n",
        "\n",
        "def except_directory(file_list):\n",
        "    out_of_classification = \"except_directory\"\n",
        "    result_dict = {}\n",
        "\n",
        "    for file in file_list:\n",
        "        result_dict[file] = out_of_classification\n",
        "\n",
        "    return result_dict"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MphdSiPtiOSt"
      },
      "source": [
        "directory_list = ['넷마블', '대통령', '민주당', '모모랜드', '레드벨벳', '빅히트', '소프트', '코스피', '텔레콤', '트롯', '포토']\n",
        "file_list = ['코스피외국인개인매수에코앞까지코스닥돌파.txt', '더불어민주당미래입법과제상임위간사단연석회의.txt', '자급제아이폰분실보험가입일부터가능.txt', '모모랜드주이자가격리붐대신스페셜등장어마어마하게떨려붐붐파워.txt', '넷마블월드시즌챕터업데이트.txt', '코스피사흘연속사상최고치경신.txt', '민주당미래입법과제상임위간사단연석회의.txt', '텔레콤맵안드로이드오토베타테스트론칭.txt', '놀면뭐하니톱귀유재석추억의주크박스오픈만여명과깜짝라이브.txt', '발라드그룹순순희신곡전부다주지말걸발표.txt', '트롯신홍원빈테스형으로열정무대패자부활전탈락에도극찬.txt', '넷마블월드새로운챕터성카드추가.txt', '코스피는오르고환율은내리고.txt', '자급제아이폰써도분실보험가입가능해진다.txt', '장동민배다해선넘는사생활피해에곤혹이슈톡.txt', '코스피사상최고치경신.txt', '다시뒤집힌전동킥보드법무면허규제법행안위통과.txt', '빅히트레이블즈가지테마로펼쳐진다.txt', '자급제아이폰일부터분실보험가입가능.txt', '코스피사상최고치.txt', '텔레콤자급제아이폰도분실보험가입된다.txt', '소프트웨이브디지털전환사이버보안이핵심.txt', '이낙연공수처법반드시완수많이인내했고결단임박.txt', '세일즈포스고급차브랜드벤틀리에솔루션공급.txt', '코스피다시역대최고가마감.txt', '모모랜드주이붐붐파워대타상큼미모.txt', '코스피종가기준최고치경신.txt', '미래입법과제상임위간사단연석회의참석하는이낙연김태년.txt', '대통령절차적정당성공정성당부추미애징계위연기.txt', '레드벨벳아이린오랜만에근황화보촬영스타.txt', '코스피마감사흘연속사상최고치경신.txt', '코스피일째사상최고원달러환율원대.txt', '소프트웨이브플렌옵틱콘텐츠저작기술.txt', '트롯신이떴다홍원빈테스형으로레전드무대선사.txt', '미래입법과제발언하는이낙연대표.txt', '코스피일연속최고치경신선목전서마감종합.txt', '코스피마감또최고치경신선눈앞.txt', '코스피거침없는질주오르며사흘째최고치경신.txt', '민주당국회자리에아파트짓자는건토건포퓰리즘.txt', '포토하하별후딱끝내고갈게.txt', '표시장거래현황.txt', '크루미디어지콤위시트레이닝센터업무제휴계약체결.txt', '민주당미래입법과제연석회의.txt', '대통령절차적정당공정성강조에징계위일로연기.txt', '코스피하루만에최고치경신.txt', '윤보미김민경비장함감도는마녀들포스터운동신들케미에기대.txt', '발언하는이낙연대표.txt', '대통령이용구징계위원장배제지시했지만공정성논쟁은여전.txt', '미래입법과제상임위간사단연석회의.txt', '자급제아이폰고객도분실보험가입된다.txt', '모모랜드낸시나윤한복전도사뿜뿜.txt', '대화하는이낙연한정애.txt', '텔레콤빅테크마케팅컴퍼니로조직개편.txt', '레드벨벳아이린갑질논란후첫근황미모에물올랐네스타.txt', '코스피최고치경신눈앞삼성전자장중만원첫돌파.txt', '소프트웨이브모아소프트등분석시험도구공개.txt', '빅히트뉴이어스이브라이브.txt', '목요대화참석자와인사하는정세균총리.txt', '코스피사상최고치원달러환율원붕괴.txt', '소프트웨이브혁신기술선보인다스타트업총출동.txt', '소프트웨이브플랫폼부터의료진단시스템까지신기술총출동.txt', '자급제아이폰도일부터분실보험가입가능.txt', '김태희싸이다이아몬드수저스타상위집안연중라이브.txt', '목소리내는여당전의원들추미애가검찰개혁어렵게해.txt', '자급제아이폰분실보험가입월일부터가능.txt', '발언하는김태년원내대표.txt', '코스피일째사상최고치.txt', '코스피사흘연속사상최고치경신선눈앞.txt', '트롯전국체전트로트전쟁서막알리는예고편공개.txt', '코스피역대최고가로마감.txt', '트롯전국체전레전드라인업과함께트로트시대연다.txt', '빅히트패밀리콘서트에서도본다새해카운트다운무대공개.txt', '자급제아이폰도분실보험가능.txt', '민주당권력기관개혁마무리수순야당공수처결사반대.txt', '소프트웨이브국내대표솔루션업계차세대먹거리로미래준비한다.txt', '코스피일째사상최고선코앞.txt', '스브스타남자로살겠다선언한엘리엇페이지에배우자도지지자랑스러워.txt', '단독박명수이찬원밀접접촉자개뼈다귀녹화연기.txt', 'untitled.ui', '민주국민의힘김은혜대변인즉각적인사과촉구.txt', '미래입법과제연석회의참석하는이낙연김태년.txt']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdv22YdMiYfz"
      },
      "source": [
        "# 제목 기반 자동 분류\n",
        "def title_classification(directory_list, file_list):\n",
        "\n",
        "    result_dict = {}\n",
        "    index_dict = {}\n",
        "\n",
        "    origin_directory_list = directory_list.copy()\n",
        "\n",
        "    origin_file_list = file_list.copy()\n",
        "\n",
        "    # 첫번째 단계 : 데이터 전처리 (data preprocess)\n",
        "    tmp_dir_list = data_preprocess(directory_list)\n",
        "    tmp_file_list = data_preprocess(file_list)\n",
        "\n",
        "    # 두번째 단계 : 단순 유사도 검사 (simplest_classification)\n",
        "    index_dict = simplest_classification(tmp_dir_list, tmp_file_list)\n",
        "\n",
        "    ## Save classificated file\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "\n",
        "    ### Remove classificated file\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # 세번째 단계 : Word2Vec를 이용한 유사도 검사 (word2vec_similarity)\n",
        "    index_dict = word2vec_similarity(tmp_dir_list, tmp_file_list)\n",
        "\n",
        "    ## Save classificated file\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "\n",
        "    ### Remove classificated file\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # 네번째 단계 : 자모단위 유사도 검사 (Phonology classification)\n",
        "    index_dict = Phonology_classification(tmp_dir_list, tmp_file_list)\n",
        "\n",
        "    ## Save classificated file\n",
        "    result_dict.update(save_classificated_file(index_dict, origin_file_list, origin_directory_list))\n",
        "\n",
        "    ### Remove classificated file\n",
        "    tmp_file_list = rm_classificated_file(index_dict, tmp_file_list)\n",
        "    origin_file_list = rm_classificated_file(index_dict, origin_file_list)\n",
        "\n",
        "    # 다섯번째 단계 : 예외 처리 (except_directory)\n",
        "    result_dict.update(except_directory(origin_file_list))\n",
        "\n",
        "    # Change dictionary to result\n",
        "    result_list = dict_to_list(result_dict)\n",
        "\n",
        "    return result_list"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWelqjojxvjl"
      },
      "source": [
        "res = title_classification(directory_list, file_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llGhKy7psmJ4",
        "outputId": "35bb108f-3332-4014-e99d-2632170c8d71"
      },
      "source": [
        "for i in res:\n",
        "  print(i, end=\"\\n\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "코스피/코스피외국인개인매수에코앞까지코스닥돌파\n",
            "민주당/더불어민주당미래입법과제상임위간사단연석회의\n",
            "모모랜드/모모랜드주이자가격리붐대신스페셜등장어마어마하게떨려붐붐파워\n",
            "넷마블/넷마블월드시즌챕터업데이트\n",
            "민주당/민주당미래입법과제상임위간사단연석회의\n",
            "트롯/트롯신홍원빈테스형으로열정무대패자부활전탈락에도극찬\n",
            "넷마블/넷마블월드새로운챕터성카드추가\n",
            "코스피/코스피는오르고환율은내리고\n",
            "코스피/코스피사상최고치경신\n",
            "코스피/코스피사상최고치\n",
            "코스피/코스피다시역대최고가마감\n",
            "모모랜드/모모랜드주이붐붐파워대타상큼미모\n",
            "코스피/코스피종가기준최고치경신\n",
            "대통령/대통령절차적정당성공정성당부추미애징계위연기\n",
            "레드벨벳/레드벨벳아이린오랜만에근황화보촬영스타\n",
            "코스피/코스피마감사흘연속사상최고치경신\n",
            "트롯/트롯신이떴다홍원빈테스형으로레전드무대선사\n",
            "코스피/코스피거침없는질주오르며사흘째최고치경신\n",
            "민주당/민주당국회자리에아파트짓자는건토건포퓰리즘\n",
            "포토/포토하하별후딱끝내고갈게\n",
            "민주당/민주당미래입법과제연석회의\n",
            "대통령/대통령절차적정당공정성강조에징계위일로연기\n",
            "모모랜드/모모랜드낸시나윤한복전도사뿜뿜\n",
            "레드벨벳/레드벨벳아이린갑질논란후첫근황미모에물올랐네스타\n",
            "코스피/코스피최고치경신눈앞삼성전자장중만원첫돌파\n",
            "코스피/코스피사상최고치원달러환율원붕괴\n",
            "코스피/코스피일째사상최고치\n",
            "코스피/코스피사흘연속사상최고치경신선눈앞\n",
            "트롯/트롯전국체전트로트전쟁서막알리는예고편공개\n",
            "코스피/코스피역대최고가로마감\n",
            "트롯/트롯전국체전레전드라인업과함께트로트시대연다\n",
            "빅히트/빅히트패밀리콘서트에서도본다새해카운트다운무대공개\n",
            "민주당/민주당권력기관개혁마무리수순야당공수처결사반대\n",
            "텔레콤/자급제아이폰분실보험가입일부터가능\n",
            "트롯/코스피사흘연속사상최고치경신\n",
            "텔레콤/텔레콤맵안드로이드오토베타테스트론칭\n",
            "트롯/놀면뭐하니톱귀유재석추억의주크박스오픈만여명과깜짝라이브\n",
            "트롯/발라드그룹순순희신곡전부다주지말걸발표\n",
            "텔레콤/자급제아이폰써도분실보험가입가능해진다\n",
            "포토/장동민배다해선넘는사생활피해에곤혹이슈톡\n",
            "트롯/다시뒤집힌전동킥보드법무면허규제법행안위통과\n",
            "트롯/빅히트레이블즈가지테마로펼쳐진다\n",
            "텔레콤/자급제아이폰일부터분실보험가입가능\n",
            "텔레콤/텔레콤자급제아이폰도분실보험가입된다\n",
            "텔레콤/소프트웨이브디지털전환사이버보안이핵심\n",
            "텔레콤/이낙연공수처법반드시완수많이인내했고결단임박\n",
            "텔레콤/세일즈포스고급차브랜드벤틀리에솔루션공급\n",
            "민주당/미래입법과제상임위간사단연석회의참석하는이낙연김태년\n",
            "레드벨벳/코스피일째사상최고원달러환율원대\n",
            "텔레콤/소프트웨이브플렌옵틱콘텐츠저작기술\n",
            "민주당/미래입법과제발언하는이낙연대표\n",
            "텔레콤/코스피일연속최고치경신선목전서마감종합\n",
            "포토/코스피마감또최고치경신선눈앞\n",
            "텔레콤/표시장거래현황\n",
            "텔레콤/크루미디어지콤위시트레이닝센터업무제휴계약체결\n",
            "트롯/코스피하루만에최고치경신\n",
            "민주당/윤보미김민경비장함감도는마녀들포스터운동신들케미에기대\n",
            "민주당/발언하는이낙연대표\n",
            "민주당/대통령이용구징계위원장배제지시했지만공정성논쟁은여전\n",
            "민주당/미래입법과제상임위간사단연석회의\n",
            "텔레콤/자급제아이폰고객도분실보험가입된다\n",
            "포토/대화하는이낙연한정애\n",
            "텔레콤/텔레콤빅테크마케팅컴퍼니로조직개편\n",
            "포토/소프트웨이브모아소프트등분석시험도구공개\n",
            "트롯/빅히트뉴이어스이브라이브\n",
            "대통령/목요대화참석자와인사하는정세균총리\n",
            "텔레콤/소프트웨이브혁신기술선보인다스타트업총출동\n",
            "텔레콤/소프트웨이브플랫폼부터의료진단시스템까지신기술총출동\n",
            "텔레콤/자급제아이폰도일부터분실보험가입가능\n",
            "트롯/김태희싸이다이아몬드수저스타상위집안연중라이브\n",
            "민주당/목소리내는여당전의원들추미애가검찰개혁어렵게해\n",
            "텔레콤/자급제아이폰분실보험가입월일부터가능\n",
            "민주당/발언하는김태년원내대표\n",
            "텔레콤/자급제아이폰도분실보험가능\n",
            "텔레콤/소프트웨이브국내대표솔루션업계차세대먹거리로미래준비한다\n",
            "트롯/코스피일째사상최고선코앞\n",
            "트롯/스브스타남자로살겠다선언한엘리엇페이지에배우자도지지자랑스러워\n",
            "트롯/단독박명수이찬원밀접접촉자개뼈다귀녹화연기\n",
            "대통령/untitled\n",
            "민주당/민주국민의힘김은혜대변인즉각적인사과촉구\n",
            "대통령/미래입법과제연석회의참석하는이낙연김태년\n"
          ]
        }
      ]
    }
  ]
}